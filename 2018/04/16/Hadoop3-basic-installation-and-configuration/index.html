

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" href="/img/android-chrome-192x192.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Suncle Chen">
  <meta name="keywords" content="">
  
    <meta name="description" content="搭建hadoop  为了体验HDFS和MapReduce框架，以及在HDFS上运行示例程序或简单作业，我们首先需要完成单机上的Hadoop安装。所依赖的软件环境如下：  Linux系统：以运行在阿里云ECS上的Ubuntu 16.04 LTS版本为例 jdk-8u162-linux-x64.tar.gz hadoop 3.1.0  本次演示统一将软件放置在&#x2F;usr&#x2F;local&#x2F;src目录中">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop3单机和伪分布式模式安装配置">
<meta property="og:url" content="https://suncle.me/2018/04/16/Hadoop3-basic-installation-and-configuration/index.html">
<meta property="og:site_name" content="Suncle">
<meta property="og:description" content="搭建hadoop  为了体验HDFS和MapReduce框架，以及在HDFS上运行示例程序或简单作业，我们首先需要完成单机上的Hadoop安装。所依赖的软件环境如下：  Linux系统：以运行在阿里云ECS上的Ubuntu 16.04 LTS版本为例 jdk-8u162-linux-x64.tar.gz hadoop 3.1.0  本次演示统一将软件放置在&#x2F;usr&#x2F;local&#x2F;src目录中">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2018-04-16T11:08:28.000Z">
<meta property="article:modified_time" content="2022-08-25T03:37:44.438Z">
<meta property="article:author" content="Suncle Chen">
<meta property="article:tag" content="安装">
<meta property="article:tag" content="配置">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary_large_image">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>Hadoop3单机和伪分布式模式安装配置 - Suncle</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"suncle.me","root":"/","version":"1.9.2","typing":{"enable":false,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":"41fc030db57d5570dd22f78997dc4a7e","google":"UA-72506112-1","gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="Suncle" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 60vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Suncle&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/newsletter/">
                <i class="iconfont icon-mail"></i>
                周刊
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                更多
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/">
                    <i class="iconfont icon-category-fill"></i>
                    分类
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/tags/">
                    <i class="iconfont icon-tags-fill"></i>
                    标签
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/atom.xml">
                    <i class="iconfont icon-rss-fill"></i>
                    RSS
                  </a>
                
              </div>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/suncle-banner.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">Hadoop3单机和伪分布式模式安装配置</span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2018-04-16 19:08" pubdate>
          2018年4月16日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          6k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          50 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar category-bar" style="margin-right: -1rem">
    





<div class="category-list">
  
  
    
    
    
    <div class="category row nomargin-x">
      <a class="category-item 
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="大数据"
        id="heading-2c657e7dce6effaecbb458deb45e800a" role="tab" data-toggle="collapse" href="#collapse-2c657e7dce6effaecbb458deb45e800a"
        aria-expanded="true"
      >
        大数据
        <span class="list-group-count">(12)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse show" id="collapse-2c657e7dce6effaecbb458deb45e800a"
           role="tabpanel" aria-labelledby="heading-2c657e7dce6effaecbb458deb45e800a">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/2019/07/27/clickhouse-build-distributed-cluster/" title="Clickhouse分布式集群搭建"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Clickhouse分布式集群搭建</span>
        </a>
      
    
      
      
        <a href="/2019/07/27/clickhouse-create-distributed-table-and-table-engine-introduction/" title="Clickhouse创建分布式表以及表引擎介绍"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Clickhouse创建分布式表以及表引擎介绍</span>
        </a>
      
    
      
      
        <a href="/2019/07/27/clickhouse-introduction-and-comparison-of-performance/" title="Clickhouse简介和性能对比"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Clickhouse简介和性能对比</span>
        </a>
      
    
      
      
        <a href="/2018/04/16/Hadoop3-basic-installation-and-configuration/" title="Hadoop3单机和伪分布式模式安装配置"
           class="list-group-item list-group-item-action
           active">
          <span class="category-post">Hadoop3单机和伪分布式模式安装配置</span>
        </a>
      
    
      
      
        <a href="/2018/04/16/Hadoop-MapReduce-HDFS-Introduction/" title="Hadoop、MapReduce、HDFS介绍"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Hadoop、MapReduce、HDFS介绍</span>
        </a>
      
    
      
      
        <a href="/2018/05/16/Hadoop-Project-Live-Flow-Statistic/" title="Hadoop项目：从cdn日志统计直播流量"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Hadoop项目：从cdn日志统计直播流量</span>
        </a>
      
    
      
      
        <a href="/2018/05/09/Sqoop-Import-Export/" title="Sqoop导入导出"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Sqoop导入导出</span>
        </a>
      
    
      
      
        <a href="/2018/04/17/Writing-An-Hadoop-MapReduce-Program-In-Python/" title="使用Python语言写Hadoop MapReduce程序"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">使用Python语言写Hadoop MapReduce程序</span>
        </a>
      
    
      
      
        <a href="/2019/08/02/Comparison-of-the-Open-Source-OLAP-Systems-for-BigData/" title="大数据OLAP系统比较"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">大数据OLAP系统比较</span>
        </a>
      
    
      
      
        <a href="/2018/05/03/Building-Hadoop3-Cluster/" title="搭建Hadoop3集群"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">搭建Hadoop3集群</span>
        </a>
      
    
      
      
        <a href="/2019/05/08/brief-introduction-and-comparison-of-data-warehouse/" title="数仓工作的简单介绍和对比"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">数仓工作的简单介绍和对比</span>
        </a>
      
    
      
      
        <a href="/2019/07/30/Aliyun-big-data-infrastructure-components-research/" title="阿里云大数据基础组件调研"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">阿里云大数据基础组件调研</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
</div>


  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Hadoop3单机和伪分布式模式安装配置</h1>
            
            
              <div class="markdown-body">
                
                <blockquote>
<p>搭建hadoop</p>
</blockquote>
<p>为了体验HDFS和MapReduce框架，以及在HDFS上运行示例程序或简单作业，我们首先需要完成单机上的Hadoop安装。所依赖的软件环境如下：</p>
<ol>
<li>Linux系统：以运行在阿里云ECS上的Ubuntu 16.04 LTS版本为例</li>
<li>jdk-8u162-linux-x64.tar.gz</li>
<li>hadoop 3.1.0</li>
</ol>
<p>本次演示统一将软件放置在<code>/usr/local/src</code>目录中</p>
<span id="more"></span>

<h1 id="创建hadoop用户"><a href="#创建hadoop用户" class="headerlink" title="创建hadoop用户"></a>创建hadoop用户</h1><p>首先需要建立一个hadoop用户，用来启动Hadoop的进程，这样避免使用root用户启动进程，这也是比较规范的服务器用户管理，使用以下命令创建hadoop用户：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">useradd -m hadoop -s /bin/bash<br>passwd hadoop  <span class="hljs-comment"># 为hadoop用户设置密码，直接设置为hadoop</span><br>adduser hadoop sudo  <span class="hljs-comment"># 为 hadoop 用户增加管理员权限，方便部署</span><br></code></pre></td></tr></table></figure>

<p>后续均在hadoop用户中操作。</p>
<p><strong>免密码ssh设置</strong></p>
<p>Hadoop中namenode需要启动集群中的所有机器的Hadoop守护进程，而这个过程需要通过SSH登录来实现。而Hadoop并没有提供SSH输入密码的登录形式，因此为了保证可以顺利登录每台机器，需要将所有机器配置为namenode可以无密码登录它们。所以我们需要配置SSH的无密码访问（注意无密码访问是为hadoop用户配置的，故以下操作需要在hadoop用户下完成）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh-keygen -t rsa -P <span class="hljs-string">&#x27;&#x27;</span> -f ~/.ssh/id_rsa<br><span class="hljs-built_in">cat</span> ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys<br><span class="hljs-built_in">chmod</span> 0600 ~/.ssh/authorized_keys<br></code></pre></td></tr></table></figure>

<p>此时再用 <code>ssh localhost</code> 命令，无需输入密码就可以直接登陆了（第一次需要先输入一个yes）</p>
<h1 id="Java安装配置"><a href="#Java安装配置" class="headerlink" title="Java安装配置"></a>Java安装配置</h1><p>下载地址：<code>https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</code></p>
<p>执行以下命令解压</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /usr/local/src<br>tar -xzvf jdk-8u162-linux-x64.tar.gz<br></code></pre></td></tr></table></figure>

<p>然后编辑<code>~/.profile</code>文件，在文件结尾处增加以下内容：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># java jdk env settings</span><br>JAVA_HOME=/usr/local/src/jdk1.8.0_162<br>PATH=<span class="hljs-variable">$&#123;JAVA_HOME&#125;</span>/bin:<span class="hljs-variable">$PATH</span><br><span class="hljs-built_in">export</span> JAVA_HOME PATH<br></code></pre></td></tr></table></figure>

<p>修改完成之后使用source命令使配置生效：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">source</span> ~/.profile<br></code></pre></td></tr></table></figure>

<p>若输出JAVA_HOME环境变量有结果则说明修改成功：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-variable">$JAVA_HOME</span><br></code></pre></td></tr></table></figure>

<p>此时可以使用验证java环境变量是否配置成功：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">java -version<br></code></pre></td></tr></table></figure>

<h1 id="Hadoop安装配置"><a href="#Hadoop安装配置" class="headerlink" title="Hadoop安装配置"></a>Hadoop安装配置</h1><p>下载地址：<code>https://hadoop.apache.org/releases.html</code></p>
<p>Hadoop的运行有三种形式：</p>
<ul>
<li>单实例运行</li>
<li>伪分布式</li>
<li>完全分布式</li>
</ul>
<p>本次主要介绍单实例和伪分布式Hadoop的安装以及使用简介。首先需要先配置hadoop的环境变量。</p>
<p>编辑<code>~/.profile</code>文件，在文件结尾处增加以下内容：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># hadoop install env settings</span><br>HADOOP_INSTALL=/usr/local/src/hadoop-3.1.0<br>PATH=<span class="hljs-variable">$HADOOP_INSTALL</span>/bin:<span class="hljs-variable">$HADOOP_INSTALL</span>/sbin:<span class="hljs-variable">$PATH</span><br><span class="hljs-built_in">export</span> HADOOP_INSTALL PATH<br></code></pre></td></tr></table></figure>

<h2 id="单机模式"><a href="#单机模式" class="headerlink" title="单机模式"></a>单机模式</h2><p>单机模式（<strong>standalone</strong>）是Hadoop的默认模式。当首次解压Hadoop的源码包时，Hadoop无法了解硬件安装环境，便保守地选择了最小配置。在这种默认模式下所有3个XML文件均为空。当配置文件为空时，Hadoop会完全运行在本地。因为不需要与其他节点交互，单机模式就不使用HDFS，也不加载任何Hadoop的守护进程。该模式主要用于开发调试MapReduce程序的应用逻辑。</p>
<blockquote>
<p>此程序一般不建议安装，网络上很少这方面资料</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /usr/local/src<br>tar -xzvf hadoop-3.1.0.tar.gz<br></code></pre></td></tr></table></figure>

<p>解压完成之后测试安装是否正常：执行命令<code>hadoop</code>，正常情况应该显示hadoop的命令使用文档。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">hadoop<br>hadoop version<br></code></pre></td></tr></table></figure>

<p>也可以运行MapReduce任务，执行如下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> hadoop-3.1.0/<br><span class="hljs-built_in">mkdir</span> input<br><span class="hljs-built_in">cp</span> etc/hadoop/*.xml input<br>bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.0.jar grep input output <span class="hljs-string">&#x27;dfs[a-z.]+&#x27;</span><br></code></pre></td></tr></table></figure>

<p>执行完成之后可以发现output文件夹中生成了两个文件<code>part-r-00000</code>和<code>_SUCCESS</code>，其中<code>part-r-00000</code>文件中记录着在input目录中的所有xml文件中上述正则表达式匹配成功的单词的数量。可以使用以下命令检查结果是否正确。</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">grep -5 <span class="hljs-params">--color</span> <span class="hljs-string">&quot;dfs&quot;</span> *<span class="hljs-string">.xml</span><br></code></pre></td></tr></table></figure>

<p>在hadoop3.1版本中的所有xml文件中只有<code>dfsadmin</code>这个单词出现了一次。</p>
<h2 id="伪分布模式"><a href="#伪分布模式" class="headerlink" title="伪分布模式"></a>伪分布模式</h2><p>伪分布模式（<strong>Pseudo-Distributed Mode</strong>）在“单节点集群”上运行Hadoop，其中所有的守护进程都运行在同一台机器上。该模式在单机模式之上增加了代码调试功能，允许你检查内存使用情况，HDFS输入输出，以及其他的守护进程交互。</p>
<blockquote>
<p>namenode，datanode，secondarynamenode，jobtracer，tasktracer这5个进程，都能在集群上看到。</p>
</blockquote>
<p>伪分布式模式只需要在单机模式的基础上改两个配置文件并且格式化namenode即可。</p>
<p>编辑文件<code>etc/hadoop/core-site.xml</code>：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/usr/local/src/hadoop-3.1.0/tmp<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">description</span>&gt;</span>Abase for other temporary directories.<span class="hljs-tag">&lt;/<span class="hljs-name">description</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://localhost:9000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>

<p>编辑文件<code>etc/hadoop/hdfs-site.xml</code>：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.name.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/usr/local/src/hadoop-3.1.0/tmp/dfs/name<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.datanode.data.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/usr/local/src/hadoop-3.1.0/tmp/dfs/data<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>

<blockquote>
<p>Hadoop配置文件说明：</p>
<p>Hadoop 的运行方式是由配置文件决定的（运行 Hadoop 时会读取配置文件），因此如果需要从伪分布式模式切换回单机模式，需要删除 core-site.xml 中的配置项。</p>
<p>此外，伪分布式虽然只需要配置 fs.defaultFS 和 dfs.replication 就可以运行（官方教程如此），不过若没有配置 hadoop.tmp.dir 参数，则默认使用的临时目录为 &#x2F;tmp&#x2F;hadoo-hadoop，而这个目录在重启时有可能被系统清理掉，导致必须重新执行 format 才行。所以我们进行了设置，同时也指定 dfs.namenode.name.dir 和 dfs.datanode.data.dir，否则在接下来的步骤中可能会出错。</p>
</blockquote>
<p>配置完成后，执行 namenode  的格式化：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hdfs namenode -format<br></code></pre></td></tr></table></figure>

<p>然后使用<code>start-dfs.sh</code>命令启动NameNode daemon进程和DataNode daemon进程：</p>
<p>在启动前需要修改<code>etc/hadoop/hadoop-env.sh</code>文件中的<code>JAVA_HOME</code>变量，改为实际的即可：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Many of the options here are built from the perspective that users</span><br><span class="hljs-comment"># may want to provide OVERWRITING values on the command line.</span><br><span class="hljs-comment"># For example:</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#  JAVA_HOME=/usr/java/testing hdfs dfs -ls</span><br>JAVA_HOME=/usr/local/src/jdk1.8.0_162<br><span class="hljs-comment">#</span><br><span class="hljs-comment"># Therefore, the vast majority (BUT NOT ALL!) of these defaults</span><br><span class="hljs-comment"># are configured for substitution and not append.  If append</span><br><span class="hljs-comment"># is preferable, modify this file accordingly.</span><br></code></pre></td></tr></table></figure>

<p>启动完成后，可以通过命令 <code>jps</code> 来判断是否成功启动，若成功启动则会列出如下进程: “NameNode”、”DataNode” 和 “SecondaryNameNode”（如果 SecondaryNameNode 没有启动，请运行 sbin&#x2F;stop-dfs.sh 关闭进程，然后再次尝试启动尝试）。如果没有 NameNode 或 DataNode ，那就是配置不成功，请仔细检查之前步骤，或通过查看启动日志排查原因。</p>
<p>启动成功之后，浏览NameNode的web接口，Web界面示例地址如下（hadoop2.x端口默认为50070，hadoop3.x端口默认为9870）：</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">http:<span class="hljs-regexp">//</span><span class="hljs-number">120.77</span>.<span class="hljs-number">239.67</span>:<span class="hljs-number">9870</span><br></code></pre></td></tr></table></figure>

<p>上面的单机模式，grep 例子读取的是本地数据，伪分布式读取的则是 HDFS 上的数据。要使用 HDFS，首先需要在 HDFS 中创建用户目录：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hdfs dfs -<span class="hljs-built_in">mkdir</span> -p /user/hadoop<br></code></pre></td></tr></table></figure>

<p>接着将 <code>etc/hadoop</code> 中的 xml 文件作为输入文件复制到分布式文件系统中，即将 <code>/usr/local/src/hadoop-3.1.0/etc/hadoop</code> 目录下的xml文件复制到分布式文件系统中的 &#x2F;user&#x2F;hadoop&#x2F;input 中。我们使用的是 hadoop 用户，并且已创建相应的用户目录 &#x2F;user&#x2F;hadoop ，因此在命令中就可以使用相对路径如 input，其对应的绝对路径就是 &#x2F;user&#x2F;hadoop&#x2F;input：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">hdfs dfs -<span class="hljs-built_in">mkdir</span> input<br>hdfs dfs -put ./etc/hadoop/*.xml input<br></code></pre></td></tr></table></figure>

<p>复制完成后，可以通过如下命令查看文件列表：</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stata">hdfs dfs -<span class="hljs-keyword">ls</span> <span class="hljs-keyword">input</span><br></code></pre></td></tr></table></figure>

<p>伪分布式运行 MapReduce 作业的方式跟单机模式相同，区别在于伪分布式读取的是HDFS中的文件（可以将单机步骤中创建的本地 input 文件夹，输出结果 output 文件夹都删掉来验证这一点）。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.0.jar grep input output <span class="hljs-string">&#x27;dfs[a-z.]+&#x27;</span><br></code></pre></td></tr></table></figure>

<p>查看运行结果的命令（查看的是位于 HDFS 中的输出结果）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hdfs dfs -<span class="hljs-built_in">cat</span> output/*<br></code></pre></td></tr></table></figure>

<p>结果如下，注意到刚才我们已经更改了配置文件，所以运行结果不同。</p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs elixir">hadoop<span class="hljs-variable">@iZwz9367lkujh8ulgxc2cwZ</span><span class="hljs-symbol">:/usr/local/src/hadoop-</span><span class="hljs-number">3.1</span>.<span class="hljs-number">0</span><span class="hljs-variable">$ </span> hdfs dfs -cat output/*<br><span class="hljs-number">1</span>	dfsadmin<br><span class="hljs-number">1</span>	dfs.replication<br><span class="hljs-number">1</span>	dfs.namenode.name.dir<br><span class="hljs-number">1</span>	dfs.datanode.data.dir<br></code></pre></td></tr></table></figure>

<p>也可以将运行结果取回到本地：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">./bin/hdfs dfs -get output ./output     <span class="hljs-comment"># 将 HDFS 上的 output 文件夹取回到本机</span><br><span class="hljs-built_in">cat</span> ./output/*<br></code></pre></td></tr></table></figure>

<p>Hadoop 运行程序时，输出目录不能存在，否则会提示错误org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs:&#x2F;&#x2F;localhost:9000&#x2F;user&#x2F;hadoop&#x2F;output already exists，因此若要再次执行，需要执行如下命令删除 output 文件夹：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hdfs dfs -<span class="hljs-built_in">rm</span> -r output<br></code></pre></td></tr></table></figure>

<p>若要关闭 Hadoop，则运行</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">stop</span>-dfs.<span class="hljs-keyword">sh</span><br></code></pre></td></tr></table></figure>

<p>下次启动 hadoop 时，无需进行 NameNode 的初始化，只需要运行 <code>start-dfs.sh</code> 就可以！</p>
<hr>
<p>参考：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/muyi_amen/article/details/62423649">https://blog.csdn.net/muyi_amen/article/details/62423649</a></li>
<li><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r1.0.4/cn/quickstart.html">https://hadoop.apache.org/docs/r1.0.4/cn/quickstart.html</a></li>
<li><a target="_blank" rel="noopener" href="http://www.aboutyun.com/thread-6839-1-1.html">http://www.aboutyun.com/thread-6839-1-1.html</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/e450fe10d003">https://www.jianshu.com/p/e450fe10d003</a></li>
<li><a target="_blank" rel="noopener" href="http://dblab.xmu.edu.cn/blog/install-hadoop/">http://dblab.xmu.edu.cn/blog/install-hadoop/</a></li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" class="category-chain-item">大数据</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E5%AE%89%E8%A3%85/">#安装</a>
      
        <a href="/tags/%E9%85%8D%E7%BD%AE/">#配置</a>
      
        <a href="/tags/Hadoop/">#Hadoop</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Hadoop3单机和伪分布式模式安装配置</div>
      <div>https://suncle.me/2018/04/16/Hadoop3-basic-installation-and-configuration/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Suncle Chen</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2018年4月16日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2018/04/17/Writing-An-Hadoop-MapReduce-Program-In-Python/" title="使用Python语言写Hadoop MapReduce程序">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">使用Python语言写Hadoop MapReduce程序</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2018/04/16/Hadoop-MapReduce-HDFS-Introduction/" title="Hadoop、MapReduce、HDFS介绍">
                        <span class="hidden-mobile">Hadoop、MapReduce、HDFS介绍</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'suncle1993/suncle1993.github.io');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
