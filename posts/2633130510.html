<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png"><link rel="icon" href="/img/android-chrome-192x192.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#2f4154"><meta name="author" content="Suncle Chen"><meta name="keywords" content=""><meta name="description" content="Apache Sqoop是一种用于在Apache Hadoop和结构化数据存储（如关系数据库）之间高效传输批量数据的工具。实质就是将导入导出命令转换成mapreduce程序来实现。 Sqoop版本选择根据官网介绍，当前（文档编写时间：2018-05-07）最新的稳定版本是1.4.7。 Sqoop2的最新版本是1.99.7（下载，文档）。 请注意，1.99.7与1.4.7不兼容，且未完成功能，具体信"><meta property="og:type" content="article"><meta property="og:title" content="Sqoop导入导出"><meta property="og:url" content="https://suncle.me/posts/2633130510.html"><meta property="og:site_name" content="Suncle"><meta property="og:description" content="Apache Sqoop是一种用于在Apache Hadoop和结构化数据存储（如关系数据库）之间高效传输批量数据的工具。实质就是将导入导出命令转换成mapreduce程序来实现。 Sqoop版本选择根据官网介绍，当前（文档编写时间：2018-05-07）最新的稳定版本是1.4.7。 Sqoop2的最新版本是1.99.7（下载，文档）。 请注意，1.99.7与1.4.7不兼容，且未完成功能，具体信"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2018-05-09T07:17:50.000Z"><meta property="article:modified_time" content="2022-08-25T17:31:49.684Z"><meta property="article:author" content="Suncle Chen"><meta property="article:tag" content="Hadoop"><meta property="article:tag" content="HDFS"><meta property="article:tag" content="Sqoop"><meta name="twitter:card" content="summary_large_image"><meta name="referrer" content="no-referrer-when-downgrade"><title>Sqoop导入导出 - Suncle</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"suncle.me",root:"/",version:"1.9.2",typing:{enable:!1,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:"41fc030db57d5570dd22f78997dc4a7e",google:"UA-72506112-1",gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="Suncle" type="application/atom+xml">
</head><body><header><div class="header-inner" style="height:60vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Suncle&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/categories/newsletter/"><i class="iconfont icon-mail"></i> 周刊</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><i class="iconfont icon-books"></i> 更多</a><div class="dropdown-menu" aria-labelledby="navbarDropdown"><a class="dropdown-item" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类 </a><a class="dropdown-item" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签 </a><a class="dropdown-item" href="/atom.xml"><i class="iconfont icon-rss-fill"></i> RSS</a></div></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/suncle-banner.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle">Sqoop导入导出</span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2018-05-09 15:17" pubdate>2018年5月9日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 13k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 105 分钟</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar category-bar" style="margin-right:-1rem"><div class="category-list"><div class="category row nomargin-x"><a class="category-item list-group-item category-item-action col-10 col-md-11 col-xm-11" title="大数据" id="heading-2c657e7dce6effaecbb458deb45e800a" role="tab" data-toggle="collapse" href="#collapse-2c657e7dce6effaecbb458deb45e800a" aria-expanded="true">大数据 <span class="list-group-count">(12)</span> <i class="iconfont icon-arrowright"></i></a><div class="category-collapse collapse show" id="collapse-2c657e7dce6effaecbb458deb45e800a" role="tabpanel" aria-labelledby="heading-2c657e7dce6effaecbb458deb45e800a"><div class="category-post-list"><a href="/posts/847397348.html" title="Clickhouse分布式集群搭建" class="list-group-item list-group-item-action"><span class="category-post">Clickhouse分布式集群搭建</span> </a><a href="/posts/4183645254.html" title="Clickhouse创建分布式表以及表引擎介绍" class="list-group-item list-group-item-action"><span class="category-post">Clickhouse创建分布式表以及表引擎介绍</span> </a><a href="/posts/1205905514.html" title="Clickhouse简介和性能对比" class="list-group-item list-group-item-action"><span class="category-post">Clickhouse简介和性能对比</span> </a><a href="/posts/4062227706.html" title="Hadoop3单机和伪分布式模式安装配置" class="list-group-item list-group-item-action"><span class="category-post">Hadoop3单机和伪分布式模式安装配置</span> </a><a href="/posts/3530117200.html" title="Hadoop、MapReduce、HDFS介绍" class="list-group-item list-group-item-action"><span class="category-post">Hadoop、MapReduce、HDFS介绍</span> </a><a href="/posts/3914716723.html" title="Hadoop项目：从cdn日志统计直播流量" class="list-group-item list-group-item-action"><span class="category-post">Hadoop项目：从cdn日志统计直播流量</span> </a><a href="/posts/2633130510.html" title="Sqoop导入导出" class="list-group-item list-group-item-action active"><span class="category-post">Sqoop导入导出</span> </a><a href="/posts/2322046866.html" title="使用Python语言写Hadoop MapReduce程序" class="list-group-item list-group-item-action"><span class="category-post">使用Python语言写Hadoop MapReduce程序</span> </a><a href="/posts/1499000154.html" title="大数据OLAP系统比较" class="list-group-item list-group-item-action"><span class="category-post">大数据OLAP系统比较</span> </a><a href="/posts/1943368759.html" title="搭建Hadoop3集群" class="list-group-item list-group-item-action"><span class="category-post">搭建Hadoop3集群</span> </a><a href="/posts/2688010521.html" title="数仓工作的简单介绍和对比" class="list-group-item list-group-item-action"><span class="category-post">数仓工作的简单介绍和对比</span> </a><a href="/posts/3266734121.html" title="阿里云大数据基础组件调研" class="list-group-item list-group-item-action"><span class="category-post">阿里云大数据基础组件调研</span></a></div></div></div></div></aside></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">Sqoop导入导出</h1><div class="markdown-body"><p>Apache Sqoop是一种用于在Apache Hadoop和结构化数据存储（如关系数据库）之间高效传输批量数据的工具。实质就是将导入导出命令转换成mapreduce程序来实现。</p><h1 id="Sqoop版本选择"><a href="#Sqoop版本选择" class="headerlink" title="Sqoop版本选择"></a>Sqoop版本选择</h1><p>根据官网介绍，当前（文档编写时间：2018-05-07）最新的稳定版本是1.4.7。 Sqoop2的最新版本是1.99.7（下载，文档）。 请注意，1.99.7与1.4.7不兼容，且未完成功能，具体信息可以参见Apache Sqoop官网。因此不适用于生产部署。所以我们选择1.4.7版本。</p><ul><li>1.4.7版本下载地址：<a target="_blank" rel="noopener" href="https://www.apache.org/dyn/closer.lua/sqoop/1.4.7">https://www.apache.org/dyn/closer.lua/sqoop/1.4.7</a></li></ul><blockquote><p>可以选择华中科技大学的镜像站进行下载：<a target="_blank" rel="noopener" href="http://mirrors.hust.edu.cn/apache/sqoop/1.4.7">http://mirrors.hust.edu.cn/apache/sqoop/1.4.7</a></p></blockquote><ul><li>1.4.7版本文档地址：<a target="_blank" rel="noopener" href="https://sqoop.apache.org/docs/1.4.7/index.html">https://sqoop.apache.org/docs/1.4.7/index.html</a></li></ul><span id="more"></span><h1 id="Sqoop安装配置"><a href="#Sqoop安装配置" class="headerlink" title="Sqoop安装配置"></a>Sqoop安装配置</h1><p>上传sqoop安装包sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz到&#x2F;usr&#x2F;local&#x2F;src目录中，解压并改名：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /usr/local/src/<br>tar xvfz sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz<br>mv sqoop-1.4.7.bin__hadoop-2.6.0 sqoop<br></code></pre></td></tr></table></figure><p>配置SQOOP_HOME到环境变量中，<code>vim ~/.profile</code>，然后写入以下内容（根据实际情况修改）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">sqoop install <span class="hljs-built_in">env</span> settings</span><br>export SQOOP_HOME=/usr/local/src/sqoop<br>export PATH=$PATH:$SQOOP_HOME:$SQOOP_HOME/bin<br></code></pre></td></tr></table></figure><p>配置sqoop-env.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /usr/local/src/sqoop/conf<br>mv sqoop-env-template.sh sqoop-env.sh<br></code></pre></td></tr></table></figure><p>然后使用 <code>vim sqoop-env.sh</code> 命令，打开文件添加如下内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">Set path to <span class="hljs-built_in">where</span> bin/hadoop is available</span><br>export HADOOP_COMMON_HOME=/usr/local/src/hadoop-3.1.0<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">Set path to <span class="hljs-built_in">where</span> hadoop-*-core.jar is available</span><br>export HADOOP_MAPRED_HOME=/usr/local/src/hadoop-3.1.0<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">set</span> the path to <span class="hljs-built_in">where</span> bin/hbase is available</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">export</span> HBASE_HOME=</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">Set the path to <span class="hljs-built_in">where</span> bin/hive is available</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">export</span> HIVE_HOME=</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">Set the path <span class="hljs-keyword">for</span> <span class="hljs-built_in">where</span> zookeper config <span class="hljs-built_in">dir</span> is</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-built_in">export</span> ZOOCFGDIR=</span><br></code></pre></td></tr></table></figure><p>如果数据读取不涉及hbase和hive，那么相关hbase和hive的配置可以不加；如果集群有独立的zookeeper集群，那么配置zookeeper，反之，不用配置。因为本次主要是使用Sqoop从Mysql导入数据到HDFS和使用Sqoop导出HDFS数据到Mysql，所以不需要配置这三项，但是会出现harmless warnning，不过没影响。</p><p>将mysql-connector-java.jar文件复制到sqoop&#x2F;lib文件夹下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /usr/local/src/<br>wget https://cdn.mysql.com//Downloads/Connector-J/mysql-connector-java-5.1.46.tar.gz<br>tar xvfz mysql-connector-java-5.1.46.tar.gz<br>cp mysql-connector-java-5.1.46/mysql-connector-java-5.1.46-bin.jar /usr/local/src/sqoop/lib/<br></code></pre></td></tr></table></figure><p><strong>测试运行</strong></p><p>使用vps中的数据库测试，数据库url为ip</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">列出mysql server中所有的数据库</span><br>hadoop@iZwz9367lkujh8ulgxc2cwZ:/usr/local/src/sqoop/lib$ sqoop list-databases --connect jdbc:mysql://138.68.1.61:3306/ --username root -P<br>2018-05-07 17:05:13,057 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7<br>Enter password: <br>2018-05-07 17:05:15,646 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.<br>information_schema<br>mysql<br>performance_schema<br>wordpress<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">列出数据库中的所有表</span><br>hadoop@iZwz9367lkujh8ulgxc2cwZ:/usr/local/src/sqoop/lib$ sqoop list-tables --connect jdbc:mysql://138.68.1.61:3306/wordpress --username root -P<br>2018-05-07 17:07:37,570 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7<br>Enter password: <br>2018-05-07 17:07:39,948 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.<br>wp_commentmeta<br>wp_comments<br>wp_pic_postmeta<br>wp_pic_posts<br>...<br></code></pre></td></tr></table></figure><p>sqoop 命令执行成功，代表安装成功，数据库连接成功。</p><p>如果使用阿里云RDS进行连接测试，需要配置RDS和本地的DNS，以便支持阿里云RDS的连接。如果不做配置会有如下报错：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-number">2018</span>-<span class="hljs-number">05</span>-<span class="hljs-number">07</span> <span class="hljs-number">16</span>:<span class="hljs-number">54</span>:<span class="hljs-number">23</span>,<span class="hljs-number">169</span> ERROR sqoop<span class="hljs-selector-class">.Sqoop</span>: Got exception running Sqoop: java<span class="hljs-selector-class">.lang</span><span class="hljs-selector-class">.RuntimeException</span>: com<span class="hljs-selector-class">.mysql</span><span class="hljs-selector-class">.jdbc</span><span class="hljs-selector-class">.exceptions</span><span class="hljs-selector-class">.jdbc4</span><span class="hljs-selector-class">.CommunicationsException</span>: Communications link failure<br></code></pre></td></tr></table></figure><h1 id="Sqoop从Mysql导入数据到HDFS"><a href="#Sqoop从Mysql导入数据到HDFS" class="headerlink" title="Sqoop从Mysql导入数据到HDFS"></a>Sqoop从Mysql导入数据到HDFS</h1><p>新建Mysql测试表tb_roommate：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs mysql">CREATE TABLE `tb_roommate` (<br>  `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT &#x27;ID&#x27;,<br>  `name_1` VARCHAR(30) NOT NULL COMMENT &#x27;姓名&#x27;,<br>  `age` TINYINT(3) UNSIGNED NOT NULL COMMENT &#x27;年龄&#x27;,<br>  `height` TINYINT(3) UNSIGNED NOT NULL COMMENT &#x27;身高&#x27;,<br>  PRIMARY KEY (`id`),<br>  UNIQUE KEY `uk_name` (`name_1`)<br>) ENGINE=INNODB DEFAULT CHARSET=utf8 COMMENT=&#x27;室友表&#x27;<br></code></pre></td></tr></table></figure><p>插入测试数据：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs mysql">INSERT INTO tb_roommate(name_1, age, height) VALUES(&#x27;ChenLiang&#x27;, 24, 182);<br>INSERT INTO tb_roommate(name_1, age, height) VALUES(&#x27;NieMing&#x27;, 23, 173);<br>INSERT INTO tb_roommate(name_1, age, height) VALUES(&#x27;LvShaohe&#x27;, 23, 172);<br>INSERT INTO tb_roommate(name_1, age, height) VALUES(&#x27;LiXuyun&#x27;, 22, 173);<br>COMMIT;<br></code></pre></td></tr></table></figure><p>查询待处理结果集：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mysql">SELECT * FROM tb_roommate WHERE age &gt; 22;<br></code></pre></td></tr></table></figure><p>数据导入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><code class="hljs shell">hadoop@node-master:~/workspace$ sqoop import --connect jdbc:mysql://138.68.1.61:3306/wordpress --username root --password XXXXXX --table tb_roommate<br>Warning: /usr/local/src/sqoop/../hbase does not exist! HBase imports will fail.<br>Please set $HBASE_HOME to the root of your HBase installation.<br>Warning: /usr/local/src/sqoop/../hcatalog does not exist! HCatalog jobs will fail.<br>Please set $HCAT_HOME to the root of your HCatalog installation.<br>Warning: /usr/local/src/sqoop/../accumulo does not exist! Accumulo imports will fail.<br>Please set $ACCUMULO_HOME to the root of your Accumulo installation.<br>Warning: /usr/local/src/sqoop/../zookeeper does not exist! Accumulo imports will fail.<br>Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.<br>2018-05-09 09:47:44,962 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7<br>2018-05-09 09:47:45,011 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.<br>2018-05-09 09:47:45,202 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.<br>2018-05-09 09:47:45,203 INFO tool.CodeGenTool: Beginning code generation<br>2018-05-09 09:47:47,328 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `tb_roommate` AS t LIMIT 1<br>2018-05-09 09:47:48,371 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `tb_roommate` AS t LIMIT 1<br>2018-05-09 09:47:49,053 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/local/src/hadoop-3.1.0<br>Note: /tmp/sqoop-hadoop/compile/6b2ce87c6baaca5f524499832b6b1bdd/tb_roommate.java uses or overrides a deprecated API.<br>Note: Recompile with -Xlint:deprecation for details.<br>2018-05-09 09:47:51,122 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-hadoop/compile/6b2ce87c6baaca5f524499832b6b1bdd/tb_roommate.jar<br>2018-05-09 09:47:51,134 WARN manager.MySQLManager: It looks like you are importing from mysql.<br>2018-05-09 09:47:51,134 WARN manager.MySQLManager: This transfer can be faster! Use the --direct<br>2018-05-09 09:47:51,134 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.<br>2018-05-09 09:47:51,134 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)<br>2018-05-09 09:47:51,813 INFO mapreduce.ImportJobBase: Beginning import of tb_roommate<br>2018-05-09 09:47:51,814 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address<br>2018-05-09 09:47:52,013 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar<br>2018-05-09 09:47:53,671 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps<br>2018-05-09 09:47:53,816 INFO client.RMProxy: Connecting to ResourceManager at node-master/120.77.239.67:18040<br>2018-05-09 09:47:54,816 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/hadoop/.staging/job_1525781821036_0013<br>2018-05-09 09:50:15,455 INFO db.DBInputFormat: Using read commited transaction isolation<br>2018-05-09 09:50:15,629 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(`id`), MAX(`id`) FROM `tb_roommate`<br>2018-05-09 09:50:15,804 INFO db.IntegerSplitter: Split size: 0; Num splits: 4 from: 1 to: 4<br>2018-05-09 09:50:16,198 INFO mapreduce.JobSubmitter: number of splits:4<br>2018-05-09 09:50:16,237 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled<br>2018-05-09 09:50:16,817 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1525781821036_0013<br>2018-05-09 09:50:16,819 INFO mapreduce.JobSubmitter: Executing with tokens: []<br>2018-05-09 09:50:17,053 INFO conf.Configuration: resource-types.xml not found<br>2018-05-09 09:50:17,054 INFO resource.ResourceUtils: Unable to find &#x27;resource-types.xml&#x27;.<br>2018-05-09 09:50:17,169 INFO impl.YarnClientImpl: Submitted application application_1525781821036_0013<br>2018-05-09 09:50:17,217 INFO mapreduce.Job: The url to track the job: http://node-master:18088/proxy/application_1525781821036_0013/<br>2018-05-09 09:50:17,218 INFO mapreduce.Job: Running job: job_1525781821036_0013<br>2018-05-09 09:50:23,347 INFO mapreduce.Job: Job job_1525781821036_0013 running in uber mode : false<br>2018-05-09 09:50:23,348 INFO mapreduce.Job:  map 0% reduce 0%<br>2018-05-09 09:50:32,417 INFO mapreduce.Job:  map 25% reduce 0%<br>2018-05-09 09:50:41,462 INFO mapreduce.Job:  map 50% reduce 0%<br>2018-05-09 09:50:50,508 INFO mapreduce.Job:  map 75% reduce 0%<br>2018-05-09 09:50:59,550 INFO mapreduce.Job:  map 100% reduce 0%<br>2018-05-09 09:51:00,562 INFO mapreduce.Job: Job job_1525781821036_0013 completed successfully<br>2018-05-09 09:51:00,647 INFO mapreduce.Job: Counters: 32<br>	File System Counters<br>		FILE: Number of bytes read=0<br>		FILE: Number of bytes written=888404<br>		FILE: Number of read operations=0<br>		FILE: Number of large read operations=0<br>		FILE: Number of write operations=0<br>		HDFS: Number of bytes read=393<br>		HDFS: Number of bytes written=71<br>		HDFS: Number of read operations=24<br>		HDFS: Number of large read operations=0<br>		HDFS: Number of write operations=8<br>	Job Counters <br>		Launched map tasks=4<br>		Other local map tasks=4<br>		Total time spent by all maps in occupied slots (ms)=23644<br>		Total time spent by all reduces in occupied slots (ms)=0<br>		Total time spent by all map tasks (ms)=23644<br>		Total vcore-milliseconds taken by all map tasks=23644<br>		Total megabyte-milliseconds taken by all map tasks=48422912<br>	Map-Reduce Framework<br>		Map input records=4<br>		Map output records=4<br>		Input split bytes=393<br>		Spilled Records=0<br>		Failed Shuffles=0<br>		Merged Map outputs=0<br>		GC time elapsed (ms)=279<br>		CPU time spent (ms)=3990<br>		Physical memory (bytes) snapshot=953724928<br>		Virtual memory (bytes) snapshot=10424242176<br>		Total committed heap usage (bytes)=560463872<br>		Peak Map Physical memory (bytes)=262942720<br>		Peak Map Virtual memory (bytes)=2613026816<br>	File Input Format Counters <br>		Bytes Read=0<br>	File Output Format Counters <br>		Bytes Written=71<br>2018-05-09 09:51:00,654 INFO mapreduce.ImportJobBase: Transferred 71 bytes in 186.9643 seconds (0.3798 bytes/sec)<br>2018-05-09 09:51:00,657 INFO mapreduce.ImportJobBase: Retrieved 4 records.<br>hadoop@node-master:~/workspace$ hdfs dfs -ls tb_roommate<br>Found 5 items<br>-rw-r--r--   2 hadoop supergroup          0 2018-05-09 09:50 tb_roommate/_SUCCESS<br>-rw-r--r--   2 hadoop supergroup         19 2018-05-09 09:50 tb_roommate/part-m-00000<br>-rw-r--r--   2 hadoop supergroup         17 2018-05-09 09:50 tb_roommate/part-m-00001<br>-rw-r--r--   2 hadoop supergroup         18 2018-05-09 09:50 tb_roommate/part-m-00002<br>-rw-r--r--   2 hadoop supergroup         17 2018-05-09 09:50 tb_roommate/part-m-00003<br>hadoop@node-master:~/workspace$ hdfs dfs -cat tb_roommate/part-m-00000<br>1,ChenLiang,24,182<br>hadoop@node-master:~/workspace$ hdfs dfs -cat tb_roommate/part-m-00001<br>2,NieMing,23,173<br>hadoop@node-master:~/workspace$ hdfs dfs -cat tb_roommate/part-m-00002<br>3,LvShaohe,23,172<br>hadoop@node-master:~/workspace$ hdfs dfs -cat tb_roommate/part-m-00003<br>4,LiXuyun,22,173<br></code></pre></td></tr></table></figure><p>将msyql数据库wordpress中的表tb_roommate，导入到hdfs目录，默认会导入到<code>/user/hadoop/tb_roommate</code>下，其中tb_roommate为导入的表名。</p><p>如果想要数据导入速度更快，可以使用<code>--direct</code>模式，sqoop为特定的RDBMS提供直接连接器，因此传输更快</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">sqoop import <span class="hljs-params">--connect</span> jdbc<span class="hljs-function">:mysql</span>:<span class="hljs-string">//138.68.1.61</span><span class="hljs-function">:3306</span>/wordpress <span class="hljs-params">--username</span> root <span class="hljs-params">--password</span> XXXXXX <span class="hljs-params">--table</span> tb_roommate <span class="hljs-params">--direct</span><br></code></pre></td></tr></table></figure><p><strong>但是需要在每台机器上有一份mysqldump可执行文件，解决办法是复制一份mysqldump文件或者直接在每台机器上安装一个mysql数据库</strong>，如果没有mysqldump，会报如下错误：</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs subunit"><span class="hljs-keyword">Error: </span>java.io.IOException: Cannot run program &quot;mysqldump&quot;: error=2, No such file or directory<br></code></pre></td></tr></table></figure><p>如果要想导入到指定的目录，添加一个选项–target-dir：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sqoop import --connect jdbc:mysql://138.68.1.61:3306/wordpress --username root --password XXXXXX --table tb_roommate --target-dir /output/sqoop/tb_roommate<br></code></pre></td></tr></table></figure><p>因为默认执行sqoop会有4个maptasks任务，为了满足业务的需要，可以进行修改，只需要在命令后面加一个选项-m：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sqoop import --connect jdbc:mysql://138.68.1.61:3306/wordpress --username root --password XXXXXX --table tb_roommate --target-dir /output/sqoop/tb_roommate -m 1<br></code></pre></td></tr></table></figure><p>执行的过程中，如果输出目录已经存在，报错，要想输出到该目录 使用选项–delete-target-dir：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sqoop import --connect jdbc:mysql://138.68.1.61:3306/wordpress --username root --password XXXXXX --table tb_roommate --target-dir /output/sqoop/tb_roommate -m 1 --delete-target-dir<br></code></pre></td></tr></table></figure><p>如果想在原来的基础之上追加新的数据，只需要添加一个选项–append,但是注意，–append和–delete-target-dir不能同时存在：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sqoop import --connect jdbc:mysql://138.68.1.61:3306/wordpress --username root --password XXXXXX --table tb_roommate --target-dir /output/sqoop/tb_roommate -m 1 --append<br></code></pre></td></tr></table></figure><p>条件导入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sqoop import --connect jdbc:mysql://138.68.1.61:3306/wordpress --username root --password XXXXXX --table tb_roommate --target-dir /output/sqoop/tb_roommate -m 1 --append --where &quot;age &gt; 22&quot;<br></code></pre></td></tr></table></figure><p>通过sql导入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sqoop import --connect jdbc:mysql://138.68.1.61:3306/wordpress --username root --password XXXXXX --table tb_roommate --target-dir /output/sqoop/tb_roommate -m 1 --append --query &quot;SELECT id, name_1, age, height FROM tb_roommate WHERE age &gt; 22&quot;<br></code></pre></td></tr></table></figure><h1 id="Sqoop导出HDFS数据到Mysql"><a href="#Sqoop导出HDFS数据到Mysql" class="headerlink" title="Sqoop导出HDFS数据到Mysql"></a>Sqoop导出HDFS数据到Mysql</h1><p>数据导出到mysql，默认以逗号作为分隔符。导出数据到Mysql之前，表需要已经存在，否则报错</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sqoop export --connect jdbc:mysql://138.68.1.61:3306/wordpress --username root --password XXXXXX --table tb_roommate1 --export-dir /user/hadoop/tb_roommate<br></code></pre></td></tr></table></figure><p>类似于Mysql duplicate操作，如果存在就更新，不存在就插入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sqoop export --connect jdbc:mysql://138.68.1.61:3306/wordpress --username root --password XXXXXX --table tb_roommate1 --export-dir /user/hadoop/tb_roommate -m 2 --update-key id --update-mode allowinsert<br></code></pre></td></tr></table></figure><h1 id="常见错误整理"><a href="#常见错误整理" class="headerlink" title="常见错误整理"></a>常见错误整理</h1><ol><li>阿里云RDS连接不上时，先用一个本地的url中只有ip的数据库或者是腾讯Mysql数据库进行测试，确认是否有问题</li><li>命令使用过程中的warning信息，需要判断是否是harmless的</li></ol><hr><p>参考：</p><ul><li><a target="_blank" rel="noopener" href="https://sqoop.apache.org/">https://sqoop.apache.org/</a></li><li><a target="_blank" rel="noopener" href="https://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html">https://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html</a></li><li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/19ff7effcaf2">https://www.jianshu.com/p/19ff7effcaf2</a></li><li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/zhangs1986/p/7063592.html">https://www.cnblogs.com/zhangs1986/p/7063592.html</a></li><li><a target="_blank" rel="noopener" href="https://acadgild.com/blog/exporting-files-hdfs-mysql-using-sqoop/">https://acadgild.com/blog/exporting-files-hdfs-mysql-using-sqoop/</a></li><li><a target="_blank" rel="noopener" href="https://my.oschina.net/sniperLi/blog/687942">https://my.oschina.net/sniperLi/blog/687942</a></li><li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/zhangs1986/p/7052621.html">https://www.cnblogs.com/zhangs1986/p/7052621.html</a></li><li><a target="_blank" rel="noopener" href="http://blog.51cto.com/xpleaf/2090584">http://blog.51cto.com/xpleaf/2090584</a></li><li><a target="_blank" rel="noopener" href="https://www.alibabacloud.com/help/zh/doc-detail/28133.htm">https://www.alibabacloud.com/help/zh/doc-detail/28133.htm</a></li><li><a target="_blank" rel="noopener" href="https://yq.aliyun.com/articles/43799">https://yq.aliyun.com/articles/43799</a></li></ul></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" class="category-chain-item">大数据</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/Hadoop/">#Hadoop</a> <a href="/tags/HDFS/">#HDFS</a> <a href="/tags/Sqoop/">#Sqoop</a></div></div><div class="license-box my-3"><div class="license-title"><div>Sqoop导入导出</div><div>https://suncle.me/posts/2633130510.html</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Suncle Chen</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2018年5月9日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/posts/3914716723.html" title="Hadoop项目：从cdn日志统计直播流量"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">Hadoop项目：从cdn日志统计直播流量</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/posts/1943368759.html" title="搭建Hadoop3集群"><span class="hidden-mobile">搭建Hadoop3集群</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><script type="text/javascript">Fluid.utils.loadComments("#comments",(function(){var t=document.documentElement.getAttribute("data-user-color-scheme");t="dark"===t?"github-dark":"github-light",window.UtterancesThemeLight="github-light",window.UtterancesThemeDark="github-dark";var e=document.createElement("script");e.setAttribute("src","https://utteranc.es/client.js"),e.setAttribute("repo","suncle1993/suncle1993.github.io"),e.setAttribute("issue-term","pathname"),e.setAttribute("label","utterances"),e.setAttribute("theme",t),e.setAttribute("crossorigin","anonymous"),document.getElementById("comments").appendChild(e)}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var o=jQuery("#board-ctn").offset().top;window.tocbot.init({tocSelector:"#toc-body",contentSelector:".markdown-body",headingSelector:CONFIG.toc.headingSelector||"h1,h2,h3,h4,h5,h6",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",collapseDepth:CONFIG.toc.collapseDepth||0,scrollSmooth:!0,headingsOffset:-o}),t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var o=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),n=[];for(var i of o)n.push(".markdown-body > "+i.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(n.join(", "))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>