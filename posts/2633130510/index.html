<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png"><link rel="icon" href="/img/android-chrome-192x192.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#2f4154"><meta name="author" content="Suncle Chen"><meta name="keywords" content=""><meta name="description" content="Apache Sqoop是一种用于在Apache Hadoop和结构化数据存储（如关系数据库）之间高效传输批量数据的工具。实质就是将导入导出命令转换成mapreduce程序来实现。 Sqoop版本选择根据官网介绍，当前（文档编写时间：2018-05-07）最新的稳定版本是1.4.7。 Sqoop2的最新版本是1.99.7（下载，文档）。 请注意，1.99.7与1.4.7不兼容，且未完成功能，具体信"><meta property="og:type" content="article"><meta property="og:title" content="Sqoop导入导出"><meta property="og:url" content="https://suncle.me/posts/2633130510/index.html"><meta property="og:site_name" content="Suncle"><meta property="og:description" content="Apache Sqoop是一种用于在Apache Hadoop和结构化数据存储（如关系数据库）之间高效传输批量数据的工具。实质就是将导入导出命令转换成mapreduce程序来实现。 Sqoop版本选择根据官网介绍，当前（文档编写时间：2018-05-07）最新的稳定版本是1.4.7。 Sqoop2的最新版本是1.99.7（下载，文档）。 请注意，1.99.7与1.4.7不兼容，且未完成功能，具体信"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2018-05-09T07:17:50.000Z"><meta property="article:modified_time" content="2022-08-26T02:44:02.287Z"><meta property="article:author" content="Suncle Chen"><meta property="article:tag" content="Hadoop"><meta property="article:tag" content="HDFS"><meta property="article:tag" content="Sqoop"><meta name="twitter:card" content="summary_large_image"><meta name="referrer" content="no-referrer-when-downgrade"><title>Sqoop导入导出 - Suncle</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/prism/1.27.0/plugins/line-numbers/prism-line-numbers.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"suncle.me",root:"/",version:"1.9.2",typing:{enable:!1,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:"41fc030db57d5570dd22f78997dc4a7e",google:"UA-72506112-1",gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="Suncle" type="application/atom+xml">
</head><body><header><div class="header-inner" style="height:60vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Suncle&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/categories/newsletter/"><i class="iconfont icon-mail"></i> 周刊</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" target="_self" href="javascript:;" rel="external nofollow noreferrer" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><i class="iconfont icon-books"></i> 更多</a><div class="dropdown-menu" aria-labelledby="navbarDropdown"><a class="dropdown-item" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类 </a><a class="dropdown-item" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签 </a><a class="dropdown-item" href="/atom.xml"><i class="iconfont icon-rss-fill"></i> RSS</a></div></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" rel="external nofollow noreferrer" data-toggle="modal" data-target="#modalSearch" aria-label="Search">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" rel="external nofollow noreferrer" aria-label="Color Toggle">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/suncle-banner.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle">Sqoop导入导出</span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2018-05-09 15:17" pubdate>2018年5月9日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 12k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 103 分钟</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar category-bar" style="margin-right:-1rem"><div class="category-list"><div class="category row nomargin-x"><a class="category-item list-group-item category-item-action col-10 col-md-11 col-xm-11" title="大数据" id="heading-2c657e7dce6effaecbb458deb45e800a" role="tab" data-toggle="collapse" href="#collapse-2c657e7dce6effaecbb458deb45e800a" aria-expanded="true">大数据 <span class="list-group-count">(12)</span> <i class="iconfont icon-arrowright"></i></a><div class="category-collapse collapse show" id="collapse-2c657e7dce6effaecbb458deb45e800a" role="tabpanel" aria-labelledby="heading-2c657e7dce6effaecbb458deb45e800a"><div class="category-post-list"><a href="/posts/847397348/" title="Clickhouse分布式集群搭建" class="list-group-item list-group-item-action"><span class="category-post">Clickhouse分布式集群搭建</span> </a><a href="/posts/4183645254/" title="Clickhouse创建分布式表以及表引擎介绍" class="list-group-item list-group-item-action"><span class="category-post">Clickhouse创建分布式表以及表引擎介绍</span> </a><a href="/posts/1205905514/" title="Clickhouse简介和性能对比" class="list-group-item list-group-item-action"><span class="category-post">Clickhouse简介和性能对比</span> </a><a href="/posts/4062227706/" title="Hadoop3单机和伪分布式模式安装配置" class="list-group-item list-group-item-action"><span class="category-post">Hadoop3单机和伪分布式模式安装配置</span> </a><a href="/posts/3530117200/" title="Hadoop、MapReduce、HDFS介绍" class="list-group-item list-group-item-action"><span class="category-post">Hadoop、MapReduce、HDFS介绍</span> </a><a href="/posts/3914716723/" title="Hadoop项目：从cdn日志统计直播流量" class="list-group-item list-group-item-action"><span class="category-post">Hadoop项目：从cdn日志统计直播流量</span> </a><a href="/posts/2633130510/" title="Sqoop导入导出" class="list-group-item list-group-item-action active"><span class="category-post">Sqoop导入导出</span> </a><a href="/posts/2322046866/" title="使用Python语言写Hadoop MapReduce程序" class="list-group-item list-group-item-action"><span class="category-post">使用Python语言写Hadoop MapReduce程序</span> </a><a href="/posts/1499000154/" title="大数据OLAP系统比较" class="list-group-item list-group-item-action"><span class="category-post">大数据OLAP系统比较</span> </a><a href="/posts/1943368759/" title="搭建Hadoop3集群" class="list-group-item list-group-item-action"><span class="category-post">搭建Hadoop3集群</span> </a><a href="/posts/2688010521/" title="数仓工作的简单介绍和对比" class="list-group-item list-group-item-action"><span class="category-post">数仓工作的简单介绍和对比</span> </a><a href="/posts/3266734121/" title="阿里云大数据基础组件调研" class="list-group-item list-group-item-action"><span class="category-post">阿里云大数据基础组件调研</span></a></div></div></div></div></aside></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">Sqoop导入导出</h1><div class="markdown-body"><p>Apache Sqoop是一种用于在Apache Hadoop和结构化数据存储（如关系数据库）之间高效传输批量数据的工具。实质就是将导入导出命令转换成mapreduce程序来实现。</p><h1 id="Sqoop版本选择"><a href="#Sqoop版本选择" class="headerlink" title="Sqoop版本选择"></a>Sqoop版本选择</h1><p>根据官网介绍，当前（文档编写时间：2018-05-07）最新的稳定版本是1.4.7。 Sqoop2的最新版本是1.99.7（下载，文档）。 请注意，1.99.7与1.4.7不兼容，且未完成功能，具体信息可以参见Apache Sqoop官网。因此不适用于生产部署。所以我们选择1.4.7版本。</p><ul><li>1.4.7版本下载地址：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.apache.org/dyn/closer.lua/sqoop/1.4.7">https://www.apache.org/dyn/closer.lua/sqoop/1.4.7</a></li></ul><blockquote><p>可以选择华中科技大学的镜像站进行下载：<a target="_blank" rel="noopener external nofollow noreferrer" href="http://mirrors.hust.edu.cn/apache/sqoop/1.4.7">http://mirrors.hust.edu.cn/apache/sqoop/1.4.7</a></p></blockquote><ul><li>1.4.7版本文档地址：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://sqoop.apache.org/docs/1.4.7/index.html">https://sqoop.apache.org/docs/1.4.7/index.html</a></li></ul><span id="more"></span><h1 id="Sqoop安装配置"><a href="#Sqoop安装配置" class="headerlink" title="Sqoop安装配置"></a>Sqoop安装配置</h1><p>上传sqoop安装包sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz到&#x2F;usr&#x2F;local&#x2F;src目录中，解压并改名：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span> /usr/local/src/
<span class="token function">tar</span> xvfz sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz
<span class="token function">mv</span> sqoop-1.4.7.bin__hadoop-2.6.0 sqoop<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure><p>配置SQOOP_HOME到环境变量中，<code>vim ~/.profile</code>，然后写入以下内容（根据实际情况修改）：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># sqoop install env settings</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">SQOOP_HOME</span><span class="token operator">=</span>/usr/local/src/sqoop
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$SQOOP_HOME</span><span class="token builtin class-name">:</span><span class="token variable">$SQOOP_HOME</span>/bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure><p>配置sqoop-env.sh</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span> /usr/local/src/sqoop/conf
<span class="token function">mv</span> sqoop-env-template.sh sqoop-env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p>然后使用 <code>vim sqoop-env.sh</code> 命令，打开文件添加如下内容：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#Set path to where bin/hadoop is available</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_COMMON_HOME</span><span class="token operator">=</span>/usr/local/src/hadoop-3.1.0

<span class="token comment">#Set path to where hadoop-*-core.jar is available</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_MAPRED_HOME</span><span class="token operator">=</span>/usr/local/src/hadoop-3.1.0

<span class="token comment">#set the path to where bin/hbase is available</span>
<span class="token comment">#export HBASE_HOME=</span>

<span class="token comment">#Set the path to where bin/hive is available</span>
<span class="token comment">#export HIVE_HOME=</span>

<span class="token comment">#Set the path for where zookeper config dir is</span>
<span class="token comment">#export ZOOCFGDIR=</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>如果数据读取不涉及hbase和hive，那么相关hbase和hive的配置可以不加；如果集群有独立的zookeeper集群，那么配置zookeeper，反之，不用配置。因为本次主要是使用Sqoop从Mysql导入数据到HDFS和使用Sqoop导出HDFS数据到Mysql，所以不需要配置这三项，但是会出现harmless warnning，不过没影响。</p><p>将mysql-connector-java.jar文件复制到sqoop&#x2F;lib文件夹下：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span> /usr/local/src/
<span class="token function">wget</span> https://cdn.mysql.com//Downloads/Connector-J/mysql-connector-java-5.1.46.tar.gz
<span class="token function">tar</span> xvfz mysql-connector-java-5.1.46.tar.gz
<span class="token function">cp</span> mysql-connector-java-5.1.46/mysql-connector-java-5.1.46-bin.jar /usr/local/src/sqoop/lib/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p><strong>测试运行</strong></p><p>使用vps中的数据库测试，数据库url为ip</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 列出mysql server中所有的数据库</span>
hadoop@iZwz9367lkujh8ulgxc2cwZ:/usr/local/src/sqoop/lib$ sqoop list-databases <span class="token parameter variable">--connect</span> jdbc:mysql://138.68.1.61:3306/ <span class="token parameter variable">--username</span> root <span class="token parameter variable">-P</span>
<span class="token number">2018</span>-05-07 <span class="token number">17</span>:05:13,057 INFO sqoop.Sqoop: Running Sqoop version: <span class="token number">1.4</span>.7
Enter password: 
<span class="token number">2018</span>-05-07 <span class="token number">17</span>:05:15,646 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
information_schema
mysql
performance_schema
wordpress

<span class="token comment"># 列出数据库中的所有表</span>
hadoop@iZwz9367lkujh8ulgxc2cwZ:/usr/local/src/sqoop/lib$ sqoop list-tables <span class="token parameter variable">--connect</span> jdbc:mysql://138.68.1.61:3306/wordpress <span class="token parameter variable">--username</span> root <span class="token parameter variable">-P</span>
<span class="token number">2018</span>-05-07 <span class="token number">17</span>:07:37,570 INFO sqoop.Sqoop: Running Sqoop version: <span class="token number">1.4</span>.7
Enter password: 
<span class="token number">2018</span>-05-07 <span class="token number">17</span>:07:39,948 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
wp_commentmeta
wp_comments
wp_pic_postmeta
wp_pic_posts
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>sqoop 命令执行成功，代表安装成功，数据库连接成功。</p><p>如果使用阿里云RDS进行连接测试，需要配置RDS和本地的DNS，以便支持阿里云RDS的连接。如果不做配置会有如下报错：</p><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">2018-05-07 16:54:23,169 ERROR sqoop.Sqoop: Got exception running Sqoop: java.lang.RuntimeException: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h1 id="Sqoop从Mysql导入数据到HDFS"><a href="#Sqoop从Mysql导入数据到HDFS" class="headerlink" title="Sqoop从Mysql导入数据到HDFS"></a>Sqoop从Mysql导入数据到HDFS</h1><p>新建Mysql测试表tb_roommate：</p><figure><div class="code-wrapper"><pre class="line-numbers language-mysql" data-language="mysql"><code class="language-mysql">CREATE TABLE &#96;tb_roommate&#96; (
  &#96;id&#96; BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT &#39;ID&#39;,
  &#96;name_1&#96; VARCHAR(30) NOT NULL COMMENT &#39;姓名&#39;,
  &#96;age&#96; TINYINT(3) UNSIGNED NOT NULL COMMENT &#39;年龄&#39;,
  &#96;height&#96; TINYINT(3) UNSIGNED NOT NULL COMMENT &#39;身高&#39;,
  PRIMARY KEY (&#96;id&#96;),
  UNIQUE KEY &#96;uk_name&#96; (&#96;name_1&#96;)
) ENGINE&#x3D;INNODB DEFAULT CHARSET&#x3D;utf8 COMMENT&#x3D;&#39;室友表&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>插入测试数据：</p><figure><div class="code-wrapper"><pre class="line-numbers language-mysql" data-language="mysql"><code class="language-mysql">INSERT INTO tb_roommate(name_1, age, height) VALUES(&#39;ChenLiang&#39;, 24, 182);
INSERT INTO tb_roommate(name_1, age, height) VALUES(&#39;NieMing&#39;, 23, 173);
INSERT INTO tb_roommate(name_1, age, height) VALUES(&#39;LvShaohe&#39;, 23, 172);
INSERT INTO tb_roommate(name_1, age, height) VALUES(&#39;LiXuyun&#39;, 22, 173);
COMMIT;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>查询待处理结果集：</p><figure><div class="code-wrapper"><pre class="line-numbers language-mysql" data-language="mysql"><code class="language-mysql">SELECT * FROM tb_roommate WHERE age &gt; 22;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>数据导入：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hadoop@node-master:~/workspace$ sqoop <span class="token function">import</span> <span class="token parameter variable">--connect</span> jdbc:mysql://138.68.1.61:3306/wordpress <span class="token parameter variable">--username</span> root <span class="token parameter variable">--password</span> XXXXXX <span class="token parameter variable">--table</span> tb_roommate
Warning: /usr/local/src/sqoop/<span class="token punctuation">..</span>/hbase does not exist<span class="token operator">!</span> HBase imports will fail.
Please <span class="token builtin class-name">set</span> <span class="token variable">$HBASE_HOME</span> to the root of your HBase installation.
Warning: /usr/local/src/sqoop/<span class="token punctuation">..</span>/hcatalog does not exist<span class="token operator">!</span> HCatalog <span class="token function">jobs</span> will fail.
Please <span class="token builtin class-name">set</span> <span class="token variable">$HCAT_HOME</span> to the root of your HCatalog installation.
Warning: /usr/local/src/sqoop/<span class="token punctuation">..</span>/accumulo does not exist<span class="token operator">!</span> Accumulo imports will fail.
Please <span class="token builtin class-name">set</span> <span class="token variable">$ACCUMULO_HOME</span> to the root of your Accumulo installation.
Warning: /usr/local/src/sqoop/<span class="token punctuation">..</span>/zookeeper does not exist<span class="token operator">!</span> Accumulo imports will fail.
Please <span class="token builtin class-name">set</span> <span class="token variable">$ZOOKEEPER_HOME</span> to the root of your Zookeeper installation.
<span class="token number">2018</span>-05-09 09:47:44,962 INFO sqoop.Sqoop: Running Sqoop version: <span class="token number">1.4</span>.7
<span class="token number">2018</span>-05-09 09:47:45,011 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using <span class="token parameter variable">-P</span> instead.
<span class="token number">2018</span>-05-09 09:47:45,202 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
<span class="token number">2018</span>-05-09 09:47:45,203 INFO tool.CodeGenTool: Beginning code generation
<span class="token number">2018</span>-05-09 09:47:47,328 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM <span class="token variable"><span class="token variable">`</span>tb_roommate<span class="token variable">`</span></span> AS t LIMIT <span class="token number">1</span>
<span class="token number">2018</span>-05-09 09:47:48,371 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM <span class="token variable"><span class="token variable">`</span>tb_roommate<span class="token variable">`</span></span> AS t LIMIT <span class="token number">1</span>
<span class="token number">2018</span>-05-09 09:47:49,053 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /usr/local/src/hadoop-3.1.0
Note: /tmp/sqoop-hadoop/compile/6b2ce87c6baaca5f524499832b6b1bdd/tb_roommate.java uses or overrides a deprecated API.
Note: Recompile with <span class="token parameter variable">-Xlint:deprecation</span> <span class="token keyword">for</span> details.
<span class="token number">2018</span>-05-09 09:47:51,122 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-hadoop/compile/6b2ce87c6baaca5f524499832b6b1bdd/tb_roommate.jar
<span class="token number">2018</span>-05-09 09:47:51,134 WARN manager.MySQLManager: It looks like you are importing from mysql.
<span class="token number">2018</span>-05-09 09:47:51,134 WARN manager.MySQLManager: This transfer can be faster<span class="token operator">!</span> Use the <span class="token parameter variable">--direct</span>
<span class="token number">2018</span>-05-09 09:47:51,134 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.
<span class="token number">2018</span>-05-09 09:47:51,134 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull <span class="token punctuation">(</span>mysql<span class="token punctuation">)</span>
<span class="token number">2018</span>-05-09 09:47:51,813 INFO mapreduce.ImportJobBase: Beginning <span class="token function">import</span> of tb_roommate
<span class="token number">2018</span>-05-09 09:47:51,814 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
<span class="token number">2018</span>-05-09 09:47:52,013 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
<span class="token number">2018</span>-05-09 09:47:53,671 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
<span class="token number">2018</span>-05-09 09:47:53,816 INFO client.RMProxy: Connecting to ResourceManager at node-master/120.77.239.67:18040
<span class="token number">2018</span>-05-09 09:47:54,816 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding <span class="token keyword">for</span> path: /tmp/hadoop-yarn/staging/hadoop/.staging/job_1525781821036_0013
<span class="token number">2018</span>-05-09 09:50:15,455 INFO db.DBInputFormat: Using <span class="token builtin class-name">read</span> commited transaction isolation
<span class="token number">2018</span>-05-09 09:50:15,629 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN<span class="token punctuation">(</span><span class="token variable"><span class="token variable">`</span><span class="token function">id</span><span class="token variable">`</span></span><span class="token punctuation">)</span>, MAX<span class="token punctuation">(</span><span class="token variable"><span class="token variable">`</span><span class="token function">id</span><span class="token variable">`</span></span><span class="token punctuation">)</span> FROM <span class="token variable"><span class="token variable">`</span>tb_roommate<span class="token variable">`</span></span>
<span class="token number">2018</span>-05-09 09:50:15,804 INFO db.IntegerSplitter: Split size: <span class="token number">0</span><span class="token punctuation">;</span> Num splits: <span class="token number">4</span> from: <span class="token number">1</span> to: <span class="token number">4</span>
<span class="token number">2018</span>-05-09 09:50:16,198 INFO mapreduce.JobSubmitter: number of splits:4
<span class="token number">2018</span>-05-09 09:50:16,237 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
<span class="token number">2018</span>-05-09 09:50:16,817 INFO mapreduce.JobSubmitter: Submitting tokens <span class="token keyword">for</span> job: job_1525781821036_0013
<span class="token number">2018</span>-05-09 09:50:16,819 INFO mapreduce.JobSubmitter: Executing with tokens: <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token number">2018</span>-05-09 09:50:17,053 INFO conf.Configuration: resource-types.xml not found
<span class="token number">2018</span>-05-09 09:50:17,054 INFO resource.ResourceUtils: Unable to <span class="token function">find</span> <span class="token string">'resource-types.xml'</span><span class="token builtin class-name">.</span>
<span class="token number">2018</span>-05-09 09:50:17,169 INFO impl.YarnClientImpl: Submitted application application_1525781821036_0013
<span class="token number">2018</span>-05-09 09:50:17,217 INFO mapreduce.Job: The url to track the job: http://node-master:18088/proxy/application_1525781821036_0013/
<span class="token number">2018</span>-05-09 09:50:17,218 INFO mapreduce.Job: Running job: job_1525781821036_0013
<span class="token number">2018</span>-05-09 09:50:23,347 INFO mapreduce.Job: Job job_1525781821036_0013 running <span class="token keyword">in</span> uber mode <span class="token builtin class-name">:</span> <span class="token boolean">false</span>
<span class="token number">2018</span>-05-09 09:50:23,348 INFO mapreduce.Job:  map <span class="token number">0</span>% reduce <span class="token number">0</span>%
<span class="token number">2018</span>-05-09 09:50:32,417 INFO mapreduce.Job:  map <span class="token number">25</span>% reduce <span class="token number">0</span>%
<span class="token number">2018</span>-05-09 09:50:41,462 INFO mapreduce.Job:  map <span class="token number">50</span>% reduce <span class="token number">0</span>%
<span class="token number">2018</span>-05-09 09:50:50,508 INFO mapreduce.Job:  map <span class="token number">75</span>% reduce <span class="token number">0</span>%
<span class="token number">2018</span>-05-09 09:50:59,550 INFO mapreduce.Job:  map <span class="token number">100</span>% reduce <span class="token number">0</span>%
<span class="token number">2018</span>-05-09 09:51:00,562 INFO mapreduce.Job: Job job_1525781821036_0013 completed successfully
<span class="token number">2018</span>-05-09 09:51:00,647 INFO mapreduce.Job: Counters: <span class="token number">32</span>
	File System Counters
		FILE: Number of bytes <span class="token assign-left variable">read</span><span class="token operator">=</span><span class="token number">0</span>
		FILE: Number of bytes <span class="token assign-left variable">written</span><span class="token operator">=</span><span class="token number">888404</span>
		FILE: Number of <span class="token builtin class-name">read</span> <span class="token assign-left variable">operations</span><span class="token operator">=</span><span class="token number">0</span>
		FILE: Number of large <span class="token builtin class-name">read</span> <span class="token assign-left variable">operations</span><span class="token operator">=</span><span class="token number">0</span>
		FILE: Number of <span class="token function">write</span> <span class="token assign-left variable">operations</span><span class="token operator">=</span><span class="token number">0</span>
		HDFS: Number of bytes <span class="token assign-left variable">read</span><span class="token operator">=</span><span class="token number">393</span>
		HDFS: Number of bytes <span class="token assign-left variable">written</span><span class="token operator">=</span><span class="token number">71</span>
		HDFS: Number of <span class="token builtin class-name">read</span> <span class="token assign-left variable">operations</span><span class="token operator">=</span><span class="token number">24</span>
		HDFS: Number of large <span class="token builtin class-name">read</span> <span class="token assign-left variable">operations</span><span class="token operator">=</span><span class="token number">0</span>
		HDFS: Number of <span class="token function">write</span> <span class="token assign-left variable">operations</span><span class="token operator">=</span><span class="token number">8</span>
	Job Counters 
		Launched map <span class="token assign-left variable">tasks</span><span class="token operator">=</span><span class="token number">4</span>
		Other <span class="token builtin class-name">local</span> map <span class="token assign-left variable">tasks</span><span class="token operator">=</span><span class="token number">4</span>
		Total <span class="token function">time</span> spent by all maps <span class="token keyword">in</span> occupied slots <span class="token punctuation">(</span>ms<span class="token punctuation">)</span><span class="token operator">=</span><span class="token number">23644</span>
		Total <span class="token function">time</span> spent by all reduces <span class="token keyword">in</span> occupied slots <span class="token punctuation">(</span>ms<span class="token punctuation">)</span><span class="token operator">=</span><span class="token number">0</span>
		Total <span class="token function">time</span> spent by all map tasks <span class="token punctuation">(</span>ms<span class="token punctuation">)</span><span class="token operator">=</span><span class="token number">23644</span>
		Total vcore-milliseconds taken by all map <span class="token assign-left variable">tasks</span><span class="token operator">=</span><span class="token number">23644</span>
		Total megabyte-milliseconds taken by all map <span class="token assign-left variable">tasks</span><span class="token operator">=</span><span class="token number">48422912</span>
	Map-Reduce Framework
		Map input <span class="token assign-left variable">records</span><span class="token operator">=</span><span class="token number">4</span>
		Map output <span class="token assign-left variable">records</span><span class="token operator">=</span><span class="token number">4</span>
		Input <span class="token function">split</span> <span class="token assign-left variable">bytes</span><span class="token operator">=</span><span class="token number">393</span>
		Spilled <span class="token assign-left variable">Records</span><span class="token operator">=</span><span class="token number">0</span>
		Failed <span class="token assign-left variable">Shuffles</span><span class="token operator">=</span><span class="token number">0</span>
		Merged Map <span class="token assign-left variable">outputs</span><span class="token operator">=</span><span class="token number">0</span>
		GC <span class="token function">time</span> elapsed <span class="token punctuation">(</span>ms<span class="token punctuation">)</span><span class="token operator">=</span><span class="token number">279</span>
		CPU <span class="token function">time</span> spent <span class="token punctuation">(</span>ms<span class="token punctuation">)</span><span class="token operator">=</span><span class="token number">3990</span>
		Physical memory <span class="token punctuation">(</span>bytes<span class="token punctuation">)</span> <span class="token assign-left variable">snapshot</span><span class="token operator">=</span><span class="token number">953724928</span>
		Virtual memory <span class="token punctuation">(</span>bytes<span class="token punctuation">)</span> <span class="token assign-left variable">snapshot</span><span class="token operator">=</span><span class="token number">10424242176</span>
		Total committed heap usage <span class="token punctuation">(</span>bytes<span class="token punctuation">)</span><span class="token operator">=</span><span class="token number">560463872</span>
		Peak Map Physical memory <span class="token punctuation">(</span>bytes<span class="token punctuation">)</span><span class="token operator">=</span><span class="token number">262942720</span>
		Peak Map Virtual memory <span class="token punctuation">(</span>bytes<span class="token punctuation">)</span><span class="token operator">=</span><span class="token number">2613026816</span>
	File Input Format Counters 
		Bytes <span class="token assign-left variable">Read</span><span class="token operator">=</span><span class="token number">0</span>
	File Output Format Counters 
		Bytes <span class="token assign-left variable">Written</span><span class="token operator">=</span><span class="token number">71</span>
<span class="token number">2018</span>-05-09 09:51:00,654 INFO mapreduce.ImportJobBase: Transferred <span class="token number">71</span> bytes <span class="token keyword">in</span> <span class="token number">186.9643</span> seconds <span class="token punctuation">(</span><span class="token number">0.3798</span> bytes/sec<span class="token punctuation">)</span>
<span class="token number">2018</span>-05-09 09:51:00,657 INFO mapreduce.ImportJobBase: Retrieved <span class="token number">4</span> records.
hadoop@node-master:~/workspace$ hdfs dfs <span class="token parameter variable">-ls</span> tb_roommate
Found <span class="token number">5</span> items
-rw-r--r--   <span class="token number">2</span> hadoop supergroup          <span class="token number">0</span> <span class="token number">2018</span>-05-09 09:50 tb_roommate/_SUCCESS
-rw-r--r--   <span class="token number">2</span> hadoop supergroup         <span class="token number">19</span> <span class="token number">2018</span>-05-09 09:50 tb_roommate/part-m-00000
-rw-r--r--   <span class="token number">2</span> hadoop supergroup         <span class="token number">17</span> <span class="token number">2018</span>-05-09 09:50 tb_roommate/part-m-00001
-rw-r--r--   <span class="token number">2</span> hadoop supergroup         <span class="token number">18</span> <span class="token number">2018</span>-05-09 09:50 tb_roommate/part-m-00002
-rw-r--r--   <span class="token number">2</span> hadoop supergroup         <span class="token number">17</span> <span class="token number">2018</span>-05-09 09:50 tb_roommate/part-m-00003
hadoop@node-master:~/workspace$ hdfs dfs <span class="token parameter variable">-cat</span> tb_roommate/part-m-00000
<span class="token number">1</span>,ChenLiang,24,182
hadoop@node-master:~/workspace$ hdfs dfs <span class="token parameter variable">-cat</span> tb_roommate/part-m-00001
<span class="token number">2</span>,NieMing,23,173
hadoop@node-master:~/workspace$ hdfs dfs <span class="token parameter variable">-cat</span> tb_roommate/part-m-00002
<span class="token number">3</span>,LvShaohe,23,172
hadoop@node-master:~/workspace$ hdfs dfs <span class="token parameter variable">-cat</span> tb_roommate/part-m-00003
<span class="token number">4</span>,LiXuyun,22,173<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>将msyql数据库wordpress中的表tb_roommate，导入到hdfs目录，默认会导入到<code>/user/hadoop/tb_roommate</code>下，其中tb_roommate为导入的表名。</p><p>如果想要数据导入速度更快，可以使用<code>--direct</code>模式，sqoop为特定的RDBMS提供直接连接器，因此传输更快</p><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">sqoop import --connect jdbc:mysql:&#x2F;&#x2F;138.68.1.61:3306&#x2F;wordpress --username root --password XXXXXX --table tb_roommate --direct<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>但是需要在每台机器上有一份mysqldump可执行文件，解决办法是复制一份mysqldump文件或者直接在每台机器上安装一个mysql数据库</strong>，如果没有mysqldump，会报如下错误：</p><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">Error: java.io.IOException: Cannot run program &quot;mysqldump&quot;: error&#x3D;2, No such file or directory<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>如果要想导入到指定的目录，添加一个选项–target-dir：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">sqoop <span class="token function">import</span> <span class="token parameter variable">--connect</span> jdbc:mysql://138.68.1.61:3306/wordpress <span class="token parameter variable">--username</span> root <span class="token parameter variable">--password</span> XXXXXX <span class="token parameter variable">--table</span> tb_roommate --target-dir /output/sqoop/tb_roommate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>因为默认执行sqoop会有4个maptasks任务，为了满足业务的需要，可以进行修改，只需要在命令后面加一个选项-m：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">sqoop <span class="token function">import</span> <span class="token parameter variable">--connect</span> jdbc:mysql://138.68.1.61:3306/wordpress <span class="token parameter variable">--username</span> root <span class="token parameter variable">--password</span> XXXXXX <span class="token parameter variable">--table</span> tb_roommate --target-dir /output/sqoop/tb_roommate <span class="token parameter variable">-m</span> <span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>执行的过程中，如果输出目录已经存在，报错，要想输出到该目录 使用选项–delete-target-dir：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">sqoop <span class="token function">import</span> <span class="token parameter variable">--connect</span> jdbc:mysql://138.68.1.61:3306/wordpress <span class="token parameter variable">--username</span> root <span class="token parameter variable">--password</span> XXXXXX <span class="token parameter variable">--table</span> tb_roommate --target-dir /output/sqoop/tb_roommate <span class="token parameter variable">-m</span> <span class="token number">1</span> --delete-target-dir<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>如果想在原来的基础之上追加新的数据，只需要添加一个选项–append,但是注意，–append和–delete-target-dir不能同时存在：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">sqoop <span class="token function">import</span> <span class="token parameter variable">--connect</span> jdbc:mysql://138.68.1.61:3306/wordpress <span class="token parameter variable">--username</span> root <span class="token parameter variable">--password</span> XXXXXX <span class="token parameter variable">--table</span> tb_roommate --target-dir /output/sqoop/tb_roommate <span class="token parameter variable">-m</span> <span class="token number">1</span> <span class="token parameter variable">--append</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>条件导入：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">sqoop <span class="token function">import</span> <span class="token parameter variable">--connect</span> jdbc:mysql://138.68.1.61:3306/wordpress <span class="token parameter variable">--username</span> root <span class="token parameter variable">--password</span> XXXXXX <span class="token parameter variable">--table</span> tb_roommate --target-dir /output/sqoop/tb_roommate <span class="token parameter variable">-m</span> <span class="token number">1</span> <span class="token parameter variable">--append</span> <span class="token parameter variable">--where</span> <span class="token string">"age > 22"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>通过sql导入：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">sqoop <span class="token function">import</span> <span class="token parameter variable">--connect</span> jdbc:mysql://138.68.1.61:3306/wordpress <span class="token parameter variable">--username</span> root <span class="token parameter variable">--password</span> XXXXXX <span class="token parameter variable">--table</span> tb_roommate --target-dir /output/sqoop/tb_roommate <span class="token parameter variable">-m</span> <span class="token number">1</span> <span class="token parameter variable">--append</span> <span class="token parameter variable">--query</span> <span class="token string">"SELECT id, name_1, age, height FROM tb_roommate WHERE age > 22"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h1 id="Sqoop导出HDFS数据到Mysql"><a href="#Sqoop导出HDFS数据到Mysql" class="headerlink" title="Sqoop导出HDFS数据到Mysql"></a>Sqoop导出HDFS数据到Mysql</h1><p>数据导出到mysql，默认以逗号作为分隔符。导出数据到Mysql之前，表需要已经存在，否则报错</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">sqoop <span class="token builtin class-name">export</span> <span class="token parameter variable">--connect</span> jdbc:mysql://138.68.1.61:3306/wordpress <span class="token parameter variable">--username</span> root <span class="token parameter variable">--password</span> XXXXXX <span class="token parameter variable">--table</span> tb_roommate1 --export-dir /user/hadoop/tb_roommate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>类似于Mysql duplicate操作，如果存在就更新，不存在就插入：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">sqoop <span class="token builtin class-name">export</span> <span class="token parameter variable">--connect</span> jdbc:mysql://138.68.1.61:3306/wordpress <span class="token parameter variable">--username</span> root <span class="token parameter variable">--password</span> XXXXXX <span class="token parameter variable">--table</span> tb_roommate1 --export-dir /user/hadoop/tb_roommate <span class="token parameter variable">-m</span> <span class="token number">2</span> --update-key <span class="token function">id</span> --update-mode allowinsert<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h1 id="常见错误整理"><a href="#常见错误整理" class="headerlink" title="常见错误整理"></a>常见错误整理</h1><ol><li>阿里云RDS连接不上时，先用一个本地的url中只有ip的数据库或者是腾讯Mysql数据库进行测试，确认是否有问题</li><li>命令使用过程中的warning信息，需要判断是否是harmless的</li></ol><hr><p>参考：</p><ul><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://sqoop.apache.org/">https://sqoop.apache.org/</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html">https://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.jianshu.com/p/19ff7effcaf2">https://www.jianshu.com/p/19ff7effcaf2</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.cnblogs.com/zhangs1986/p/7063592.html">https://www.cnblogs.com/zhangs1986/p/7063592.html</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://acadgild.com/blog/exporting-files-hdfs-mysql-using-sqoop/">https://acadgild.com/blog/exporting-files-hdfs-mysql-using-sqoop/</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://my.oschina.net/sniperLi/blog/687942">https://my.oschina.net/sniperLi/blog/687942</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.cnblogs.com/zhangs1986/p/7052621.html">https://www.cnblogs.com/zhangs1986/p/7052621.html</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="http://blog.51cto.com/xpleaf/2090584">http://blog.51cto.com/xpleaf/2090584</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.alibabacloud.com/help/zh/doc-detail/28133.htm">https://www.alibabacloud.com/help/zh/doc-detail/28133.htm</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://yq.aliyun.com/articles/43799">https://yq.aliyun.com/articles/43799</a></li></ul></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" class="category-chain-item">大数据</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/Hadoop/">#Hadoop</a> <a href="/tags/HDFS/">#HDFS</a> <a href="/tags/Sqoop/">#Sqoop</a></div></div><div class="license-box my-3"><div class="license-title"><div>Sqoop导入导出</div><div>https://suncle.me/posts/2633130510/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Suncle Chen</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2018年5月9日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/" rel="external nofollow noreferrer"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/posts/3914716723/" title="Hadoop项目：从cdn日志统计直播流量"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">Hadoop项目：从cdn日志统计直播流量</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/posts/1943368759/" title="搭建Hadoop3集群"><span class="hidden-mobile">搭建Hadoop3集群</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><script type="text/javascript">Fluid.utils.loadComments("#comments",(function(){var t=document.documentElement.getAttribute("data-user-color-scheme");t="dark"===t?"github-dark":"github-light",window.UtterancesThemeLight="github-light",window.UtterancesThemeDark="github-dark";var e=document.createElement("script");e.setAttribute("src","https://utteranc.es/client.js"),e.setAttribute("repo","suncle1993/suncle1993.github.io"),e.setAttribute("issue-term","pathname"),e.setAttribute("label","utterances"),e.setAttribute("theme",t),e.setAttribute("crossorigin","anonymous"),document.getElementById("comments").appendChild(e)}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var o=jQuery("#board-ctn").offset().top;window.tocbot.init({tocSelector:"#toc-body",contentSelector:".markdown-body",headingSelector:CONFIG.toc.headingSelector||"h1,h2,h3,h4,h5,h6",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",collapseDepth:CONFIG.toc.collapseDepth||0,scrollSmooth:!0,headingsOffset:-o}),t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))</script><script src="https://lib.baomitu.com/prism/1.27.0/plugins/line-numbers/prism-line-numbers.min.js"></script><script src="https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var o=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),n=[];for(var i of o)n.push(".markdown-body > "+i.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(n.join(", "))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>