

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" href="/img/android-chrome-192x192.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Suncle Chen">
  <meta name="keywords" content="">
  
    <meta name="description" content="强烈建议再搭建hadoop集群之前体验一下单机模式和伪分布式模式的搭建过程，可以参考以下链接：  https:&#x2F;&#x2F;suncle.me&#x2F;2018&#x2F;04&#x2F;16&#x2F;Hadoop3-basic-installation-and-configuration&#x2F;  开始之前本次集群搭建所依赖的软件环境如下：  Linux系统：以运行在阿里云ECS上的Ubuntu 16.04 LTS版本为例 jdk-8u162-l">
<meta property="og:type" content="article">
<meta property="og:title" content="搭建Hadoop3集群">
<meta property="og:url" content="https://suncle.me/posts/1943368759.html">
<meta property="og:site_name" content="Suncle">
<meta property="og:description" content="强烈建议再搭建hadoop集群之前体验一下单机模式和伪分布式模式的搭建过程，可以参考以下链接：  https:&#x2F;&#x2F;suncle.me&#x2F;2018&#x2F;04&#x2F;16&#x2F;Hadoop3-basic-installation-and-configuration&#x2F;  开始之前本次集群搭建所依赖的软件环境如下：  Linux系统：以运行在阿里云ECS上的Ubuntu 16.04 LTS版本为例 jdk-8u162-l">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2018-05-03T08:54:05.000Z">
<meta property="article:modified_time" content="2022-08-25T17:15:43.408Z">
<meta property="article:author" content="Suncle Chen">
<meta property="article:tag" content="集群">
<meta property="article:tag" content="搭建">
<meta property="article:tag" content="YARN">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary_large_image">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>搭建Hadoop3集群 - Suncle</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"suncle.me","root":"/","version":"1.9.2","typing":{"enable":false,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":"41fc030db57d5570dd22f78997dc4a7e","google":"UA-72506112-1","gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="Suncle" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 60vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Suncle&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/newsletter/">
                <i class="iconfont icon-mail"></i>
                周刊
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                更多
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/">
                    <i class="iconfont icon-category-fill"></i>
                    分类
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/tags/">
                    <i class="iconfont icon-tags-fill"></i>
                    标签
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/atom.xml">
                    <i class="iconfont icon-rss-fill"></i>
                    RSS
                  </a>
                
              </div>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/suncle-banner.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">搭建Hadoop3集群</span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2018-05-03 16:54" pubdate>
          2018年5月3日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          13k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          105 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar category-bar" style="margin-right: -1rem">
    





<div class="category-list">
  
  
    
    
    
    <div class="category row nomargin-x">
      <a class="category-item 
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="大数据"
        id="heading-2c657e7dce6effaecbb458deb45e800a" role="tab" data-toggle="collapse" href="#collapse-2c657e7dce6effaecbb458deb45e800a"
        aria-expanded="true"
      >
        大数据
        <span class="list-group-count">(12)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse show" id="collapse-2c657e7dce6effaecbb458deb45e800a"
           role="tabpanel" aria-labelledby="heading-2c657e7dce6effaecbb458deb45e800a">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/posts/847397348.html" title="Clickhouse分布式集群搭建"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Clickhouse分布式集群搭建</span>
        </a>
      
    
      
      
        <a href="/posts/4183645254.html" title="Clickhouse创建分布式表以及表引擎介绍"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Clickhouse创建分布式表以及表引擎介绍</span>
        </a>
      
    
      
      
        <a href="/posts/1205905514.html" title="Clickhouse简介和性能对比"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Clickhouse简介和性能对比</span>
        </a>
      
    
      
      
        <a href="/posts/4062227706.html" title="Hadoop3单机和伪分布式模式安装配置"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Hadoop3单机和伪分布式模式安装配置</span>
        </a>
      
    
      
      
        <a href="/posts/3530117200.html" title="Hadoop、MapReduce、HDFS介绍"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Hadoop、MapReduce、HDFS介绍</span>
        </a>
      
    
      
      
        <a href="/posts/3914716723.html" title="Hadoop项目：从cdn日志统计直播流量"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Hadoop项目：从cdn日志统计直播流量</span>
        </a>
      
    
      
      
        <a href="/posts/2633130510.html" title="Sqoop导入导出"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Sqoop导入导出</span>
        </a>
      
    
      
      
        <a href="/posts/2322046866.html" title="使用Python语言写Hadoop MapReduce程序"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">使用Python语言写Hadoop MapReduce程序</span>
        </a>
      
    
      
      
        <a href="/posts/1499000154.html" title="大数据OLAP系统比较"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">大数据OLAP系统比较</span>
        </a>
      
    
      
      
        <a href="/posts/1943368759.html" title="搭建Hadoop3集群"
           class="list-group-item list-group-item-action
           active">
          <span class="category-post">搭建Hadoop3集群</span>
        </a>
      
    
      
      
        <a href="/posts/2688010521.html" title="数仓工作的简单介绍和对比"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">数仓工作的简单介绍和对比</span>
        </a>
      
    
      
      
        <a href="/posts/3266734121.html" title="阿里云大数据基础组件调研"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">阿里云大数据基础组件调研</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
</div>


  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">搭建Hadoop3集群</h1>
            
            
              <div class="markdown-body">
                
                <p>强烈建议再搭建hadoop集群之前体验一下单机模式和伪分布式模式的搭建过程，可以参考以下链接：</p>
<ul>
<li><a href="https://suncle.me/2018/04/16/Hadoop3-basic-installation-and-configuration/">https://suncle.me/2018/04/16/Hadoop3-basic-installation-and-configuration/</a></li>
</ul>
<h1 id="开始之前"><a href="#开始之前" class="headerlink" title="开始之前"></a>开始之前</h1><p>本次集群搭建所依赖的软件环境如下：</p>
<ol>
<li>Linux系统：以运行在阿里云ECS上的Ubuntu 16.04 LTS版本为例</li>
<li>jdk-8u162-linux-x64.tar.gz</li>
<li>hadoop 3.1.0</li>
</ol>
<p>先了解一个概念：</p>
<blockquote>
<p><strong>Hadoop YARN</strong>： YARN是一个在所有节点上执行数据处理任务的作业调度框架。</p>
</blockquote>
<p>然后执行以下初始步骤：</p>
<ol>
<li>创建三台阿里云ECS，也可以在本地创建3台配置较好的Vmware虚拟机。分别作为hadoop集群的node-master，node1和node2（名称可以自取）。 <del>建议将每个主机名设置为节点名</del> ，一定要修改hostname。</li>
<li>为每台机器创建hadoop用户，后续如没有特殊说明，所有命令均在hadoop用户下执行。</li>
<li>在三台机器上都安装jdk，统一使用hadoop用户安装在<code>/usr/local/src</code>目录下（其他目录也可，放在用户目录下会更好，省掉权限问题），更改<code>/usr/local/src</code>目录的属主和属组为hadoop，可以使用<code>chown hadoop:hadoop /usr/local/src</code>命令更改。</li>
<li>需要在各个节点的&#x2F;bin目录下增加java可执行文件的软连接，以node2为例</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">hadoop@node2:~$ cd /bin<br>hadoop@node2:/bin$ sudo ln -s /usr/local/src/jdk1.8.0_162/bin/java java<br></code></pre></td></tr></table></figure>

<p>如果没有添加，在执行MR程序时会报错：<code>/bin/bash: /bin/java: No such file or directory</code></p>
<p>创建hadoop用户和安装jdk的步骤参见文章开头的单机和伪分布式搭建过程。</p>
<p>下面是本次集群安装的三台ECS机器的ip情况：</p>
<ul>
<li><strong>node-master</strong>: 120.77.239.67</li>
<li><strong>node1</strong>: 119.23.145.73</li>
<li><strong>node2</strong>: 119.23.141.223</li>
</ul>
<span id="more"></span>

<h1 id="Hadoop集群架构"><a href="#Hadoop集群架构" class="headerlink" title="Hadoop集群架构"></a>Hadoop集群架构</h1><p>在配置主从节点之前，了解Hadoop集群的不同组件是非常重要的。</p>
<p>主节点保存有关分布式文件系统的信息，例如ext3文件系统上的inode表，并调度资源分配。 此次搭建过程中node-master即为主节点，并运行两个守护进程：</p>
<ul>
<li><strong>NameNode</strong>：管理分布式文件系统并知道集群内存储的数据块的位置。</li>
<li><strong>ResourceManager</strong>：管理YARN作业，监管从节点上的调度进程和执行进程。</li>
</ul>
<p>从节点存储实际数据并提供处理能力来运行作业。分别是node1和node2，并运行两个守护进程：</p>
<ul>
<li><strong>DataNode</strong>：管理物理存储在节点上的实际数据。</li>
<li><strong>NodeManager</strong>：管理节点上任务的执行。</li>
</ul>
<h1 id="配置集群"><a href="#配置集群" class="headerlink" title="配置集群"></a>配置集群</h1><h2 id="在每个节点上创建主机文件"><a href="#在每个节点上创建主机文件" class="headerlink" title="在每个节点上创建主机文件"></a>在每个节点上创建主机文件</h2><p> 要想使用节点名称通信，需要编辑<code>/etc/hosts</code>文件以添加三台服务器的IP地址。</p>
<figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">120.77.239.67</span>     node-master<br><span class="hljs-number">119.23.145.73</span>     node1<br><span class="hljs-number">119.23.141.223</span>    node2<br></code></pre></td></tr></table></figure>

<p>相当于给ip取名称。</p>
<h2 id="修改所有节点hostname文件"><a href="#修改所有节点hostname文件" class="headerlink" title="修改所有节点hostname文件"></a>修改所有节点hostname文件</h2><p><strong>这一步骤一定要操作</strong>：以管理节点为例进行操作</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">sudo vim <span class="hljs-regexp">/etc/</span>hostname<br></code></pre></td></tr></table></figure>

<p>替换掉其中已有的<code>hostname</code>，写入<code>node-master</code>，和上述hosts文件中保持一致即可。</p>
<p>如果这个步骤不修改则会在后续集群中执行MapReduce程序过程中出现以下错误：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-number">2018</span>-<span class="hljs-number">05</span>-<span class="hljs-number">08</span> <span class="hljs-number">19</span>:<span class="hljs-number">50</span>:<span class="hljs-number">46</span>,<span class="hljs-number">481</span> ERROR org<span class="hljs-selector-class">.apache</span><span class="hljs-selector-class">.hadoop</span><span class="hljs-selector-class">.yarn</span><span class="hljs-selector-class">.server</span><span class="hljs-selector-class">.resourcemanager</span><span class="hljs-selector-class">.scheduler</span><span class="hljs-selector-class">.SchedulerApplicationAttempt</span>: Error trying to assign container token and NM token to an updated container container_1525778560515_0005_01_000001<br>java<span class="hljs-selector-class">.lang</span><span class="hljs-selector-class">.IllegalArgumentException</span>: java<span class="hljs-selector-class">.net</span><span class="hljs-selector-class">.UnknownHostException</span>: iZwz99xn3877js1s191xp9Z<br>        at org<span class="hljs-selector-class">.apache</span><span class="hljs-selector-class">.hadoop</span><span class="hljs-selector-class">.security</span><span class="hljs-selector-class">.SecurityUtil</span><span class="hljs-selector-class">.buildTokenService</span>(SecurityUtil<span class="hljs-selector-class">.java</span>:<span class="hljs-number">445</span>)<br>        at org<span class="hljs-selector-class">.apache</span><span class="hljs-selector-class">.hadoop</span><span class="hljs-selector-class">.yarn</span><span class="hljs-selector-class">.event</span><span class="hljs-selector-class">.AsyncDispatcher</span><span class="hljs-selector-class">.dispatch</span>(AsyncDispatcher<span class="hljs-selector-class">.java</span>:<span class="hljs-number">197</span>)<br>        at org<span class="hljs-selector-class">.apache</span><span class="hljs-selector-class">.hadoop</span><span class="hljs-selector-class">.yarn</span><span class="hljs-selector-class">.event</span>.AsyncDispatcher$<span class="hljs-number">1</span><span class="hljs-selector-class">.run</span>(AsyncDispatcher<span class="hljs-selector-class">.java</span>:<span class="hljs-number">126</span>)<br>        at java<span class="hljs-selector-class">.lang</span><span class="hljs-selector-class">.Thread</span><span class="hljs-selector-class">.run</span>(Thread<span class="hljs-selector-class">.java</span>:<span class="hljs-number">748</span>)<br>Caused by: java<span class="hljs-selector-class">.net</span><span class="hljs-selector-class">.UnknownHostException</span>: iZwz99xn3877js1s191xp9Z<br></code></pre></td></tr></table></figure>

<p>意思是管理节点无法识别从节点的hostname，因为在管理节点的hosts文件中对应的是node2，而不是node2的真是hosname，也就是iZwz99xn3877js1s191xp9Z。因此一定要修改hostname。</p>
<p>参考：<a target="_blank" rel="noopener" href="http://www.voidcn.com/article/p-dsepxqfl-pz.html">http://www.voidcn.com/article/p-dsepxqfl-pz.html</a></p>
<h2 id="为Hadoop用户分配认证密钥对"><a href="#为Hadoop用户分配认证密钥对" class="headerlink" title="为Hadoop用户分配认证密钥对"></a>为Hadoop用户分配认证密钥对</h2><p>主节点将使用ssh协议通过密钥对认证连接到其他节点，以管理群集。</p>
<p>以hadoop用户身份登录到node-master，并生成一个ssh-key（如果执行已生成过ssh-key则会提示重复，是否需要重写，此时忽略即可）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">ssh-keygen -b 4096<br></code></pre></td></tr></table></figure>

<p>将密钥复制到其他节点。 将密钥复制到节点主机本身也是一种很好的做法，这样您可以根据需要将它用作DataNode。 输入以下命令，并在询问时输入hadoop用户的密码。 如果提示是否将密钥添加到已知主机，请输入yes：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@node-master<br>ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@node1<br>ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@node2<br></code></pre></td></tr></table></figure>

<h2 id="下载hadoop安装包并上传"><a href="#下载hadoop安装包并上传" class="headerlink" title="下载hadoop安装包并上传"></a>下载hadoop安装包并上传</h2><p>以hadoop用户身份登录到node-master，将下载好的安装包上传并解压：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /usr/local/src<br>tar -xzvf jdk-8u162-linux-x64.tar.gz<br></code></pre></td></tr></table></figure>

<h2 id="设置hadoop环境变量"><a href="#设置hadoop环境变量" class="headerlink" title="设置hadoop环境变量"></a>设置hadoop环境变量</h2><p>编辑<code>~/.profile</code>文件并写入以下内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">hadoop install <span class="hljs-built_in">env</span> settings</span><br>HADOOP_INSTALL=/usr/local/src/hadoop-3.1.0<br>PATH=$HADOOP_INSTALL/bin:$HADOOP_INSTALL/sbin:$PATH<br>export HADOOP_INSTALL PATH<br></code></pre></td></tr></table></figure>

<h1 id="配置管理节点"><a href="#配置管理节点" class="headerlink" title="配置管理节点"></a>配置管理节点</h1><p>配置将在node-master上完成并复制到其他节点。</p>
<h2 id="设置hadoop依赖的java环境变量"><a href="#设置hadoop依赖的java环境变量" class="headerlink" title="设置hadoop依赖的java环境变量"></a>设置hadoop依赖的java环境变量</h2><p>修改<code>/usr/local/src/hadoop-3.1.0/etc/hadoop/hadoop-env.sh</code>文件中的<code>JAVA_HOME</code>变量，改为实际的即可：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">Many of the options here are built from the perspective that <span class="hljs-built_in">users</span></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">may want to provide OVERWRITING values on the <span class="hljs-built_in">command</span> line.</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">For example:</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"></span><br><span class="language-bash"><span class="hljs-comment">#  JAVA_HOME=/usr/java/testing hdfs dfs -ls</span></span><br>JAVA_HOME=/usr/local/src/jdk1.8.0_162<br><span class="hljs-meta prompt_">#</span><span class="language-bash"></span><br><span class="language-bash"><span class="hljs-comment"># Therefore, the vast majority (BUT NOT ALL!) of these defaults</span></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">are configured <span class="hljs-keyword">for</span> substitution and not append.  If append</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">is preferable, modify this file accordingly.</span><br></code></pre></td></tr></table></figure>

<h2 id="配置core-site-xml"><a href="#配置core-site-xml" class="headerlink" title="配置core-site.xml"></a>配置core-site.xml</h2><p>在master主机上配置hdfs地址，注意和伪分布式的略微不同，需要直接指定master节点所在的地址。在<code>/usr/local/src/hadoop-3.1.0/etc/hadoop/core-site.xml</code>文件中写入以下内容：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/usr/local/src/hadoop-3.1.0/tmp<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">description</span>&gt;</span>Abase for other temporary directories.<span class="hljs-tag">&lt;/<span class="hljs-name">description</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://node-master:9000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>

<h2 id="配置hdfs-site-xml"><a href="#配置hdfs-site-xml" class="headerlink" title="配置hdfs-site.xml"></a>配置hdfs-site.xml</h2><p>配置副本的个数及数据的存放路径，在<code>/usr/local/src/hadoop-3.1.0/etc/hadoop/hdfs-site.xml</code>文件中写入：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>2<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.name.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/usr/local/src/hadoop-3.1.0/tmp/dfs/name<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.datanode.data.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:/usr/local/src/hadoop-3.1.0/tmp/dfs/data<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li><code>dfs.replication</code> 表示数据块的副本数量，指示数据在集群中的复制次数。 您可以设置2以将所有数据复制到两个节点上。 不要设置高于实际节点数量的值。</li>
<li><code>dfs.namenode.name.dir</code> 元数据存放路径</li>
<li><code>dfs.datanode.data.dir</code> 数据节点存放路径</li>
</ul>
<h2 id="配置mapred-site-xml"><a href="#配置mapred-site-xml" class="headerlink" title="配置mapred-site.xml"></a>配置mapred-site.xml</h2><p>设置YARN为作业调度器，也就是默认的MapReduce框架，在<code>/usr/local/src/hadoop-3.1.0/etc/hadoop/mapred-site.xml</code>文件中写入：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>

<h2 id="配置yarn-site-xml文件"><a href="#配置yarn-site-xml文件" class="headerlink" title="配置yarn-site.xml文件"></a>配置yarn-site.xml文件</h2><p>在<code>/usr/local/src/hadoop-3.1.0/etc/hadoop/yarn-site.xml</code>文件中写入：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br><span class="hljs-comment">&lt;!-- Site specific YARN configuration properties --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>node-master:18040<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>node-master:18030<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>node-master:18088<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>node-master:18025<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.admin.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>node-master:18141<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/usr/local/src/hadoop-3.1.0<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.map.env<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/usr/local/src/hadoop-3.1.0<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.reduce.env<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/usr/local/src/hadoop-3.1.0<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  &lt;/property<br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>

<p>注意修改的各个<code>value</code>需要和<code>/etc/hosts</code>中的名称保持一致。</p>
<p>这三项配置一定要有：<code>yarn.app.mapreduce.am.env</code> <code>mapreduce.map.env</code> <code>mapreduce.reduce.env</code>否则在执行MR程序时会直接报错（hadoop3.1中已验证）。</p>
<p>具体错误参考：<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/47599789/hadoop-pagerank-error-when-running">https://stackoverflow.com/questions/47599789/hadoop-pagerank-error-when-running</a></p>
<h2 id="配置workers文件"><a href="#配置workers文件" class="headerlink" title="配置workers文件"></a>配置workers文件</h2><p>列出所有workers的主机名。在<code>/usr/local/src/hadoop-3.1.0/etc/hadoop/workers</code>文件中写入：</p>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs crmsh"><span class="hljs-keyword">node</span><span class="hljs-title">-master</span><br>node1<br>node2<br></code></pre></td></tr></table></figure>

<p>注意：</p>
<ol>
<li>hadoop2.x配置的是slaves文件，这里有所改变。</li>
<li>此处的worker中写入了管理节点，因此启动HDFS之后也会在管理节点所在机器创建一个DataNode。如果不想在管理节点机器中开启DataNode，则删除workers文件中的node-master配置。</li>
</ol>
<p>此外，如果想在Hadoop集群中动态增加和删除节点，则更改此文件即可。</p>
<h1 id="配置内存分配"><a href="#配置内存分配" class="headerlink" title="配置内存分配"></a>配置内存分配</h1><p>内存分配在低RAM节点上可能会很棘手，因为默认值不适用于RAM少于8GB的节点，因此在使用sqoop等命令时调用的MapReduce程序会有如下类似的报错：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Application</span> is added to the scheduler and is not yet activated. Queue&#x27;s AM resource limit exceeded. Details : AM Partition = &lt;DEFAULT_PARTITION&gt;; AM Resource Request = &lt;memory:<span class="hljs-number">2048</span>, vCores:<span class="hljs-number">1</span>&gt;; Queue Resource Limit for AM = &lt;memory:<span class="hljs-number">3072</span>, vCores:<span class="hljs-number">1</span>&gt;; User AM Resource Limit of the queue = &lt;memory:<span class="hljs-number">3072</span>, vCores:<span class="hljs-number">1</span>&gt;; Queue AM Resource Usage = &lt;memory:<span class="hljs-number">2048</span>, vCores:<span class="hljs-number">1</span>&gt;;<br></code></pre></td></tr></table></figure>

<p>这里将重点介绍如何为MapReduce作业分配内存，因为此次使用的ECS机器是4GB内存，因此为4GB RAM节点提供示例配置。</p>
<h2 id="内存分配属性"><a href="#内存分配属性" class="headerlink" title="内存分配属性"></a>内存分配属性</h2><p>YARN作业执行需要使用以下两种资源：</p>
<ul>
<li>Application Master (AM) ：负责监视应用程序并协调集群中的分布式执行程序。</li>
<li>Executors：一些由AM创建的Executors，用于真正的运行该作业。 对于MapReduce作业，executors会并行的执行map和reduce操作。</li>
</ul>
<p>两者都在从节点的容器中运行。 每个从节点都运行一个NodeManager守护进程，负责在节点上创建容器。 整个集群由一个ResourceManager管理，它根据容量要求和当前使用情况调度所有所有从节点上的容器分配。</p>
<p>需要正确配置四种类型的资源分配才能使群集正常工作。分别是：</p>
<ol>
<li>可以为单个节点上的YARN容器分配的内存大小。 这个限制应该高于其他所有的限制; 否则，容器分配会被拒绝，应用程序失败。 但是，它不应该是节点上的全部RAM。</li>
</ol>
<blockquote>
<p>这个值在<code>yarn-site.xml</code>中配置<code>yarn.nodemanager.resource.memory-mb</code>属性</p>
</blockquote>
<ol start="2">
<li>单个容器可以消耗的内存大小以及允许的最小内存分配量。 一个容器永远不会超过最大容量，否则分配将失败，并且总是以最小分配量的倍数进行RAM分配。</li>
</ol>
<blockquote>
<p>这些值在<code>yarn-site.xml</code>中配置<code>yarn.scheduler.maximum-allocation-mb</code>和<code>yarn.scheduler.minimum-allocation-mb</code>属性。</p>
</blockquote>
<ol start="3">
<li>分配给ApplicationMaster的内存大小。 是一个适合容器最大尺寸的常数值。</li>
</ol>
<blockquote>
<p>这个值在<code>mapred-site.xml</code>中配置<code>yarn.app.mapreduce.am.resource.mb</code>属性。</p>
</blockquote>
<ol start="4">
<li>分配给map和reduce操作的内存大小。应该小于最大尺寸。</li>
</ol>
<blockquote>
<p>这是在<code>mapred-site.xml</code>中配置的，其属性为<code>mapreduce.map.memory.mb</code>和<code>mapreduce.reduce.memory.mb</code>。</p>
</blockquote>
<p>具体配置参数可以参见：<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/ClusterSetup.html">https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/ClusterSetup.html</a></p>
<h2 id="各内存大小计算方式"><a href="#各内存大小计算方式" class="headerlink" title="各内存大小计算方式"></a>各内存大小计算方式</h2><p>下载内存计算脚本：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">wget https://raw.githubusercontent.com/mahadevkonar/ambari-yarn-utils/master/yarn-utils/yarn-utils.py<br></code></pre></td></tr></table></figure>

<p>使用方法：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">python</span> yarn-utils.py -c <span class="hljs-number">16</span> -m <span class="hljs-number">64</span> -d <span class="hljs-number">4</span> -k True<br></code></pre></td></tr></table></figure>

<ul>
<li>-c选项：cpu核数</li>
<li>-m选项：内存大小</li>
<li>-d选项：机器上的磁盘数量</li>
<li>-k选项：如果安装了HBase则设置为True，否则为False</li>
</ul>
<blockquote>
<p>其中：Core的数量可以通过<code>nproc</code>命令计算；内存大小可以通过<code>free -m</code>命令来计算需要换算为G;磁盘的数量可以通过<code>lsblk -s</code>或<code>sudo fdisk -l</code>命令来查看。</p>
</blockquote>
<p>计算完成之后，最后的脚本执行命令为：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs shell">hadoop@node-master:~$ python yarn-utils.py -c 2 -m 8 -d 1 -k False<br> Using cores=2 memory=8GB disks=1 hbase=False<br> Profile: cores=2 memory=6144MB reserved=2GB usableMem=6GB disks=1<br> Num Container=3<br> Container Ram=2048MB<br> Used Ram=6GB<br> Unused Ram=2GB<br> yarn.scheduler.minimum-allocation-mb=2048<br> yarn.scheduler.maximum-allocation-mb=6144<br> yarn.nodemanager.resource.memory-mb=6144<br> mapreduce.map.memory.mb=1024<br> mapreduce.map.java.opts=-Xmx819m<br> mapreduce.reduce.memory.mb=2048<br> mapreduce.reduce.java.opts=-Xmx1638m<br> yarn.app.mapreduce.am.resource.mb=1024<br> yarn.app.mapreduce.am.command-opts=-Xmx819m<br> mapreduce.task.io.sort.mb=409<br></code></pre></td></tr></table></figure>

<h2 id="8GB节点的示例配置"><a href="#8GB节点的示例配置" class="headerlink" title="8GB节点的示例配置"></a>8GB节点的示例配置</h2><table>
<thead>
<tr>
<th>属性</th>
<th>值</th>
</tr>
</thead>
<tbody><tr>
<td>yarn.nodemanager.resource.memory-mb</td>
<td>6144</td>
</tr>
<tr>
<td>yarn.scheduler.maximum-allocation-mb</td>
<td>6144</td>
</tr>
<tr>
<td>yarn.scheduler.minimum-allocation-mb</td>
<td>2048</td>
</tr>
<tr>
<td>yarn.app.mapreduce.am.resource.mb</td>
<td>1024</td>
</tr>
<tr>
<td>mapreduce.map.memory.mb</td>
<td>1024</td>
</tr>
<tr>
<td>mapreduce.reduce.memory.mb</td>
<td>2048</td>
</tr>
</tbody></table>
<p>编辑 <code>/usr/local/src/hadoop-3.1.0/etc/hadoop/yarn-site.xml</code> 文件，并增加以下行：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>6144<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>6144<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>2048<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure>

<p>编辑<code>/usr/local/src/hadoop-3.1.0/etc/hadoop/mapred-site.xml</code>文件，并增加以下行：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.app.mapreduce.am.resource.mb<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1024<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.map.memory.mb<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1024<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.reduce.memory.mb<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>2048<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure>

<h1 id="配置从节点"><a href="#配置从节点" class="headerlink" title="配置从节点"></a>配置从节点</h1><p>复制hadoop的压缩包到所有从节点（也可以使用ftp手动上传）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">scp hadoop-3.1.0.tar.gz hadoop@node1:/usr/local/src/<br>scp hadoop-3.1.0.tar.gz hadoop@node2:/usr/local/src/<br></code></pre></td></tr></table></figure>

<p>使用hadoop用户连接到所有的从节点，解压安装包：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /usr/local/src<br>tar -xzvf jdk-8u162-linux-x64.tar.gz<br></code></pre></td></tr></table></figure>

<p>复制主节点的所有hadoop配置文件到各从节点中：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">scp /usr/local/src/hadoop-3.1.0/etc/hadoop/* hadoop@node1:/usr/local/src/hadoop-3.1.0/etc/hadoop/<br>scp /usr/local/src/hadoop-3.1.0/etc/hadoop/* hadoop@node2:/usr/local/src/hadoop-3.1.0/etc/hadoop/<br></code></pre></td></tr></table></figure>

<h1 id="格式化HDFS"><a href="#格式化HDFS" class="headerlink" title="格式化HDFS"></a>格式化HDFS</h1><p>HDFS需要像任何传统文件系统一样格式化。 在node-master上，运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">hdfs namenode -format<br></code></pre></td></tr></table></figure>

<h1 id="启动停止HDFS"><a href="#启动停止HDFS" class="headerlink" title="启动停止HDFS"></a>启动停止HDFS</h1><p>通过从node-master运行以下脚本启动HDFS：</p>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs crmsh"><span class="hljs-literal">start</span>-dfs.sh<br></code></pre></td></tr></table></figure>

<p>这个命令会启动node-master上的NameNode和SecondaryNameNode，并且根据node1和node2上的配置文件分别启动node1和node2的DataNode。</p>
<p>使用jps命令检查每个节点上的进程是否启动：</p>
<figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">24053 </span>SecondaryNameNode<br><span class="hljs-symbol">23721 </span>NameNode<br><span class="hljs-symbol">23850 </span>DataNode<br><span class="hljs-symbol">24205 </span>Jps<br></code></pre></td></tr></table></figure>

<p>（如果node-master上也启动了一个DataNode那么在node-master上也能看到NodeManager）</p>
<p>在node1上jps结果如下：</p>
<figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">27387 </span>Jps<br><span class="hljs-symbol">27311 </span>DataNode<br></code></pre></td></tr></table></figure>

<p>在node2上jps结果如下：</p>
<figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">1314 </span>Jps<br><span class="hljs-symbol">1227 </span>DataNode<br></code></pre></td></tr></table></figure>

<p>要停止主节点和从节点上的HDFS，请从node-master运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">stop-dfs.sh<br></code></pre></td></tr></table></figure>

<p>在hdfs启动之后，各种hdfs命令就都可以直接在集群上使用。</p>
<p>关于hdfs安全模式的解除：重启机器等操作时会导致hdfs处于安全模式，因此需要用命令解除：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">hdfs dfsadmin -safemode leave<br></code></pre></td></tr></table></figure>

<h1 id="运行YARN"><a href="#运行YARN" class="headerlink" title="运行YARN"></a>运行YARN</h1><p>HDFS是一个分布式存储系统，它不提供任何服务来运行和调度集群中的任务。 这是YARN框架的作用。 以下部分是关于启动，监控和向YARN提交作业。</p>
<h2 id="启动停止YARN"><a href="#启动停止YARN" class="headerlink" title="启动停止YARN"></a>启动停止YARN</h2><p>运行以下脚本启动：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">start-yarn.sh<br></code></pre></td></tr></table></figure>

<p>使用jps命令检查各节点上正在运行的进程。除了前面的HDFS守护进程之外，还应该在node-master上看到ResourceManager，并在node1和node2上看到NodeManager。</p>
<p>要停止YARN，请在node-master上运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">stop-yarn.sh<br></code></pre></td></tr></table></figure>

<h2 id="监控YARN"><a href="#监控YARN" class="headerlink" title="监控YARN"></a>监控YARN</h2><p>yarn命令提供实用的命令套件程序来管理YARN集群。 还可以使用以下命令打印正在运行的节点的报告：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">yarn node -list<br></code></pre></td></tr></table></figure>

<p>如果运行错误，需要检查YARN的配置文件<code>hadoop/yarn-site.xml</code>是否配置错误。</p>
<p>可以使用以下命令获取正在运行的应用程序的列表：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">yarn application -list<br></code></pre></td></tr></table></figure>

<p>要获得yarn命令的所有可用参数，请参阅<a target="_blank" rel="noopener" href="https://community.hortonworks.com/content/supportkb/49544/hdfs-client-fails-with-unknownhostexception-when-h.html">Apache YARN文档</a></p>
<p>与HDFS一样，YARN提供了一个友好的Web UI，默认端口为8088。 具体端口可通过yarn-site.xml文件里面的yarn.resourcemanager.webapp.address配置。示例地址如下：</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">http:<span class="hljs-regexp">//</span><span class="hljs-number">120.77</span>.<span class="hljs-number">239.67</span>:<span class="hljs-number">18088</span>/cluster<br></code></pre></td></tr></table></figure>

<h2 id="提交MapReduce作业至YARN"><a href="#提交MapReduce作业至YARN" class="headerlink" title="提交MapReduce作业至YARN"></a>提交MapReduce作业至YARN</h2><p>YARN作业被打包成jar文件，并提交给YARN用命令<code>yarn jar</code>执行。</p>
<hr>
<p>参考：</p>
<ul>
<li><a href="https://suncle.me/2018/04/16/Hadoop3-basic-installation-and-configuration/">https://suncle.me/2018/04/16/Hadoop3-basic-installation-and-configuration/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/guoyuanwei/p/8583380.html">https://www.cnblogs.com/guoyuanwei/p/8583380.html</a></li>
<li><a target="_blank" rel="noopener" href="https://linode.com/docs/databases/hadoop/how-to-install-and-set-up-hadoop-cluster">https://linode.com/docs/databases/hadoop/how-to-install-and-set-up-hadoop-cluster</a></li>
<li><a target="_blank" rel="noopener" href="http://www.dajiangtai.com/community/18389.do">http://www.dajiangtai.com/community/18389.do</a></li>
<li><a target="_blank" rel="noopener" href="https://www.2cto.com/net/201610/557536.html">https://www.2cto.com/net/201610/557536.html</a></li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" class="category-chain-item">大数据</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E9%9B%86%E7%BE%A4/">#集群</a>
      
        <a href="/tags/%E6%90%AD%E5%BB%BA/">#搭建</a>
      
        <a href="/tags/YARN/">#YARN</a>
      
        <a href="/tags/Hadoop/">#Hadoop</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>搭建Hadoop3集群</div>
      <div>https://suncle.me/posts/1943368759.html</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Suncle Chen</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2018年5月3日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/posts/2633130510.html" title="Sqoop导入导出">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Sqoop导入导出</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/posts/2322046866.html" title="使用Python语言写Hadoop MapReduce程序">
                        <span class="hidden-mobile">使用Python语言写Hadoop MapReduce程序</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'suncle1993/suncle1993.github.io');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
