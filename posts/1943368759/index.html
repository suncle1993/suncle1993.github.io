<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png"><link rel="icon" href="/img/android-chrome-192x192.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#2f4154"><meta name="author" content="Suncle Chen"><meta name="keywords" content=""><meta name="description" content="强烈建议再搭建hadoop集群之前体验一下单机模式和伪分布式模式的搭建过程，可以参考以下链接：  https:&#x2F;&#x2F;suncle.me&#x2F;2018&#x2F;04&#x2F;16&#x2F;Hadoop3-basic-installation-and-configuration&#x2F;  开始之前本次集群搭建所依赖的软件环境如下：  Linux系统：以运行在阿里云ECS上的Ubuntu 16.04 LTS版本为例 jdk-8u162-l"><meta property="og:type" content="article"><meta property="og:title" content="搭建Hadoop3集群"><meta property="og:url" content="https://suncle.me/posts/1943368759/index.html"><meta property="og:site_name" content="Suncle"><meta property="og:description" content="强烈建议再搭建hadoop集群之前体验一下单机模式和伪分布式模式的搭建过程，可以参考以下链接：  https:&#x2F;&#x2F;suncle.me&#x2F;2018&#x2F;04&#x2F;16&#x2F;Hadoop3-basic-installation-and-configuration&#x2F;  开始之前本次集群搭建所依赖的软件环境如下：  Linux系统：以运行在阿里云ECS上的Ubuntu 16.04 LTS版本为例 jdk-8u162-l"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2018-05-03T08:54:05.000Z"><meta property="article:modified_time" content="2022-08-26T02:44:02.294Z"><meta property="article:author" content="Suncle Chen"><meta property="article:tag" content="集群"><meta property="article:tag" content="搭建"><meta property="article:tag" content="YARN"><meta property="article:tag" content="Hadoop"><meta name="twitter:card" content="summary_large_image"><meta name="referrer" content="no-referrer-when-downgrade"><title>搭建Hadoop3集群 - Suncle</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/prism/1.27.0/plugins/line-numbers/prism-line-numbers.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"suncle.me",root:"/",version:"1.9.2",typing:{enable:!1,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:"41fc030db57d5570dd22f78997dc4a7e",google:"UA-72506112-1",gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="Suncle" type="application/atom+xml">
</head><body><header><div class="header-inner" style="height:60vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Suncle&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/categories/newsletter/"><i class="iconfont icon-mail"></i> 周刊</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" target="_self" href="javascript:;" rel="external nofollow noreferrer" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><i class="iconfont icon-books"></i> 更多</a><div class="dropdown-menu" aria-labelledby="navbarDropdown"><a class="dropdown-item" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类 </a><a class="dropdown-item" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签 </a><a class="dropdown-item" href="/atom.xml"><i class="iconfont icon-rss-fill"></i> RSS</a></div></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" rel="external nofollow noreferrer" data-toggle="modal" data-target="#modalSearch" aria-label="Search">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" rel="external nofollow noreferrer" aria-label="Color Toggle">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/suncle-banner.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle">搭建Hadoop3集群</span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2018-05-03 16:54" pubdate>2018年5月3日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 12k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 100 分钟</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar category-bar" style="margin-right:-1rem"><div class="category-list"><div class="category row nomargin-x"><a class="category-item list-group-item category-item-action col-10 col-md-11 col-xm-11" title="大数据" id="heading-2c657e7dce6effaecbb458deb45e800a" role="tab" data-toggle="collapse" href="#collapse-2c657e7dce6effaecbb458deb45e800a" aria-expanded="true">大数据 <span class="list-group-count">(12)</span> <i class="iconfont icon-arrowright"></i></a><div class="category-collapse collapse show" id="collapse-2c657e7dce6effaecbb458deb45e800a" role="tabpanel" aria-labelledby="heading-2c657e7dce6effaecbb458deb45e800a"><div class="category-post-list"><a href="/posts/847397348/" title="Clickhouse分布式集群搭建" class="list-group-item list-group-item-action"><span class="category-post">Clickhouse分布式集群搭建</span> </a><a href="/posts/4183645254/" title="Clickhouse创建分布式表以及表引擎介绍" class="list-group-item list-group-item-action"><span class="category-post">Clickhouse创建分布式表以及表引擎介绍</span> </a><a href="/posts/1205905514/" title="Clickhouse简介和性能对比" class="list-group-item list-group-item-action"><span class="category-post">Clickhouse简介和性能对比</span> </a><a href="/posts/4062227706/" title="Hadoop3单机和伪分布式模式安装配置" class="list-group-item list-group-item-action"><span class="category-post">Hadoop3单机和伪分布式模式安装配置</span> </a><a href="/posts/3530117200/" title="Hadoop、MapReduce、HDFS介绍" class="list-group-item list-group-item-action"><span class="category-post">Hadoop、MapReduce、HDFS介绍</span> </a><a href="/posts/3914716723/" title="Hadoop项目：从cdn日志统计直播流量" class="list-group-item list-group-item-action"><span class="category-post">Hadoop项目：从cdn日志统计直播流量</span> </a><a href="/posts/2633130510/" title="Sqoop导入导出" class="list-group-item list-group-item-action"><span class="category-post">Sqoop导入导出</span> </a><a href="/posts/2322046866/" title="使用Python语言写Hadoop MapReduce程序" class="list-group-item list-group-item-action"><span class="category-post">使用Python语言写Hadoop MapReduce程序</span> </a><a href="/posts/1499000154/" title="大数据OLAP系统比较" class="list-group-item list-group-item-action"><span class="category-post">大数据OLAP系统比较</span> </a><a href="/posts/1943368759/" title="搭建Hadoop3集群" class="list-group-item list-group-item-action active"><span class="category-post">搭建Hadoop3集群</span> </a><a href="/posts/2688010521/" title="数仓工作的简单介绍和对比" class="list-group-item list-group-item-action"><span class="category-post">数仓工作的简单介绍和对比</span> </a><a href="/posts/3266734121/" title="阿里云大数据基础组件调研" class="list-group-item list-group-item-action"><span class="category-post">阿里云大数据基础组件调研</span></a></div></div></div></div></aside></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">搭建Hadoop3集群</h1><div class="markdown-body"><p>强烈建议再搭建hadoop集群之前体验一下单机模式和伪分布式模式的搭建过程，可以参考以下链接：</p><ul><li><a href="https://suncle.me/2018/04/16/Hadoop3-basic-installation-and-configuration/">https://suncle.me/2018/04/16/Hadoop3-basic-installation-and-configuration/</a></li></ul><h1 id="开始之前"><a href="#开始之前" class="headerlink" title="开始之前"></a>开始之前</h1><p>本次集群搭建所依赖的软件环境如下：</p><ol><li>Linux系统：以运行在阿里云ECS上的Ubuntu 16.04 LTS版本为例</li><li>jdk-8u162-linux-x64.tar.gz</li><li>hadoop 3.1.0</li></ol><p>先了解一个概念：</p><blockquote><p><strong>Hadoop YARN</strong>： YARN是一个在所有节点上执行数据处理任务的作业调度框架。</p></blockquote><p>然后执行以下初始步骤：</p><ol><li>创建三台阿里云ECS，也可以在本地创建3台配置较好的Vmware虚拟机。分别作为hadoop集群的node-master，node1和node2（名称可以自取）。 <del>建议将每个主机名设置为节点名</del> ，一定要修改hostname。</li><li>为每台机器创建hadoop用户，后续如没有特殊说明，所有命令均在hadoop用户下执行。</li><li>在三台机器上都安装jdk，统一使用hadoop用户安装在<code>/usr/local/src</code>目录下（其他目录也可，放在用户目录下会更好，省掉权限问题），更改<code>/usr/local/src</code>目录的属主和属组为hadoop，可以使用<code>chown hadoop:hadoop /usr/local/src</code>命令更改。</li><li>需要在各个节点的&#x2F;bin目录下增加java可执行文件的软连接，以node2为例</li></ol><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hadoop@node2:~$ <span class="token builtin class-name">cd</span> /bin
hadoop@node2:/bin$ <span class="token function">sudo</span> <span class="token function">ln</span> <span class="token parameter variable">-s</span> /usr/local/src/jdk1.8.0_162/bin/java <span class="token function">java</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p>如果没有添加，在执行MR程序时会报错：<code>/bin/bash: /bin/java: No such file or directory</code></p><p>创建hadoop用户和安装jdk的步骤参见文章开头的单机和伪分布式搭建过程。</p><p>下面是本次集群安装的三台ECS机器的ip情况：</p><ul><li><strong>node-master</strong>: 120.77.239.67</li><li><strong>node1</strong>: 119.23.145.73</li><li><strong>node2</strong>: 119.23.141.223</li></ul><span id="more"></span><h1 id="Hadoop集群架构"><a href="#Hadoop集群架构" class="headerlink" title="Hadoop集群架构"></a>Hadoop集群架构</h1><p>在配置主从节点之前，了解Hadoop集群的不同组件是非常重要的。</p><p>主节点保存有关分布式文件系统的信息，例如ext3文件系统上的inode表，并调度资源分配。 此次搭建过程中node-master即为主节点，并运行两个守护进程：</p><ul><li><strong>NameNode</strong>：管理分布式文件系统并知道集群内存储的数据块的位置。</li><li><strong>ResourceManager</strong>：管理YARN作业，监管从节点上的调度进程和执行进程。</li></ul><p>从节点存储实际数据并提供处理能力来运行作业。分别是node1和node2，并运行两个守护进程：</p><ul><li><strong>DataNode</strong>：管理物理存储在节点上的实际数据。</li><li><strong>NodeManager</strong>：管理节点上任务的执行。</li></ul><h1 id="配置集群"><a href="#配置集群" class="headerlink" title="配置集群"></a>配置集群</h1><h2 id="在每个节点上创建主机文件"><a href="#在每个节点上创建主机文件" class="headerlink" title="在每个节点上创建主机文件"></a>在每个节点上创建主机文件</h2><p>要想使用节点名称通信，需要编辑<code>/etc/hosts</code>文件以添加三台服务器的IP地址。</p><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">120.77.239.67     node-master
119.23.145.73     node1
119.23.141.223    node2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure><p>相当于给ip取名称。</p><h2 id="修改所有节点hostname文件"><a href="#修改所有节点hostname文件" class="headerlink" title="修改所有节点hostname文件"></a>修改所有节点hostname文件</h2><p><strong>这一步骤一定要操作</strong>：以管理节点为例进行操作</p><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">sudo vim &#x2F;etc&#x2F;hostname<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>替换掉其中已有的<code>hostname</code>，写入<code>node-master</code>，和上述hosts文件中保持一致即可。</p><p>如果这个步骤不修改则会在后续集群中执行MapReduce程序过程中出现以下错误：</p><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">2018-05-08 19:50:46,481 ERROR org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt: Error trying to assign container token and NM token to an updated container container_1525778560515_0005_01_000001
java.lang.IllegalArgumentException: java.net.UnknownHostException: iZwz99xn3877js1s191xp9Z
        at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:445)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:197)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:126)
        at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.UnknownHostException: iZwz99xn3877js1s191xp9Z<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>意思是管理节点无法识别从节点的hostname，因为在管理节点的hosts文件中对应的是node2，而不是node2的真是hosname，也就是iZwz99xn3877js1s191xp9Z。因此一定要修改hostname。</p><p>参考：<a target="_blank" rel="noopener external nofollow noreferrer" href="http://www.voidcn.com/article/p-dsepxqfl-pz.html">http://www.voidcn.com/article/p-dsepxqfl-pz.html</a></p><h2 id="为Hadoop用户分配认证密钥对"><a href="#为Hadoop用户分配认证密钥对" class="headerlink" title="为Hadoop用户分配认证密钥对"></a>为Hadoop用户分配认证密钥对</h2><p>主节点将使用ssh协议通过密钥对认证连接到其他节点，以管理群集。</p><p>以hadoop用户身份登录到node-master，并生成一个ssh-key（如果执行已生成过ssh-key则会提示重复，是否需要重写，此时忽略即可）：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ssh-keygen <span class="token parameter variable">-b</span> <span class="token number">4096</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>将密钥复制到其他节点。 将密钥复制到节点主机本身也是一种很好的做法，这样您可以根据需要将它用作DataNode。 输入以下命令，并在询问时输入hadoop用户的密码。 如果提示是否将密钥添加到已知主机，请输入yes：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ssh-copy-id <span class="token parameter variable">-i</span> ~/.ssh/id_rsa.pub hadoop@node-master
ssh-copy-id <span class="token parameter variable">-i</span> ~/.ssh/id_rsa.pub hadoop@node1
ssh-copy-id <span class="token parameter variable">-i</span> ~/.ssh/id_rsa.pub hadoop@node2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure><h2 id="下载hadoop安装包并上传"><a href="#下载hadoop安装包并上传" class="headerlink" title="下载hadoop安装包并上传"></a>下载hadoop安装包并上传</h2><p>以hadoop用户身份登录到node-master，将下载好的安装包上传并解压：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span> /usr/local/src
<span class="token function">tar</span> <span class="token parameter variable">-xzvf</span> jdk-8u162-linux-x64.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><h2 id="设置hadoop环境变量"><a href="#设置hadoop环境变量" class="headerlink" title="设置hadoop环境变量"></a>设置hadoop环境变量</h2><p>编辑<code>~/.profile</code>文件并写入以下内容：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># hadoop install env settings</span>
<span class="token assign-left variable">HADOOP_INSTALL</span><span class="token operator">=</span>/usr/local/src/hadoop-3.1.0
<span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token variable">$HADOOP_INSTALL</span>/bin:<span class="token variable">$HADOOP_INSTALL</span>/sbin:<span class="token environment constant">$PATH</span>
<span class="token builtin class-name">export</span> HADOOP_INSTALL <span class="token environment constant">PATH</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h1 id="配置管理节点"><a href="#配置管理节点" class="headerlink" title="配置管理节点"></a>配置管理节点</h1><p>配置将在node-master上完成并复制到其他节点。</p><h2 id="设置hadoop依赖的java环境变量"><a href="#设置hadoop依赖的java环境变量" class="headerlink" title="设置hadoop依赖的java环境变量"></a>设置hadoop依赖的java环境变量</h2><p>修改<code>/usr/local/src/hadoop-3.1.0/etc/hadoop/hadoop-env.sh</code>文件中的<code>JAVA_HOME</code>变量，改为实际的即可：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Many of the options here are built from the perspective that users</span>
<span class="token comment"># may want to provide OVERWRITING values on the command line.</span>
<span class="token comment"># For example:</span>
<span class="token comment">#</span>
<span class="token comment">#  JAVA_HOME=/usr/java/testing hdfs dfs -ls</span>
<span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/usr/local/src/jdk1.8.0_162
<span class="token comment">#</span>
<span class="token comment"># Therefore, the vast majority (BUT NOT ALL!) of these defaults</span>
<span class="token comment"># are configured for substitution and not append.  If append</span>
<span class="token comment"># is preferable, modify this file accordingly.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h2 id="配置core-site-xml"><a href="#配置core-site-xml" class="headerlink" title="配置core-site.xml"></a>配置core-site.xml</h2><p>在master主机上配置hdfs地址，注意和伪分布式的略微不同，需要直接指定master节点所在的地址。在<code>/usr/local/src/hadoop-3.1.0/etc/hadoop/core-site.xml</code>文件中写入以下内容：</p><figure><div class="code-wrapper"><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.tmp.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>file:/usr/local/src/hadoop-3.1.0/tmp<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>Abase for other temporary directories.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>fs.defaultFS<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hdfs://node-master:9000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h2 id="配置hdfs-site-xml"><a href="#配置hdfs-site-xml" class="headerlink" title="配置hdfs-site.xml"></a>配置hdfs-site.xml</h2><p>配置副本的个数及数据的存放路径，在<code>/usr/local/src/hadoop-3.1.0/etc/hadoop/hdfs-site.xml</code>文件中写入：</p><figure><div class="code-wrapper"><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.replication<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.name.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>file:/usr/local/src/hadoop-3.1.0/tmp/dfs/name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.datanode.data.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>file:/usr/local/src/hadoop-3.1.0/tmp/dfs/data<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>其中：</p><ul><li><code>dfs.replication</code> 表示数据块的副本数量，指示数据在集群中的复制次数。 您可以设置2以将所有数据复制到两个节点上。 不要设置高于实际节点数量的值。</li><li><code>dfs.namenode.name.dir</code> 元数据存放路径</li><li><code>dfs.datanode.data.dir</code> 数据节点存放路径</li></ul><h2 id="配置mapred-site-xml"><a href="#配置mapred-site-xml" class="headerlink" title="配置mapred-site.xml"></a>配置mapred-site.xml</h2><p>设置YARN为作业调度器，也就是默认的MapReduce框架，在<code>/usr/local/src/hadoop-3.1.0/etc/hadoop/mapred-site.xml</code>文件中写入：</p><figure><div class="code-wrapper"><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>mapreduce.framework.name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>yarn<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h2 id="配置yarn-site-xml文件"><a href="#配置yarn-site-xml文件" class="headerlink" title="配置yarn-site.xml文件"></a>配置yarn-site.xml文件</h2><p>在<code>/usr/local/src/hadoop-3.1.0/etc/hadoop/yarn-site.xml</code>文件中写入：</p><figure><div class="code-wrapper"><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
<span class="token comment">&lt;!-- Site specific YARN configuration properties --></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node-master:18040<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.scheduler.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node-master:18030<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.webapp.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node-master:18088<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.resource-tracker.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node-master:18025<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.admin.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>node-master:18141<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.aux-services<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>mapreduce_shuffle<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>org.apache.hadoop.mapred.ShuffleHandler<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.app.mapreduce.am.env<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>HADOOP_MAPRED_HOME=/usr/local/src/hadoop-3.1.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>mapreduce.map.env<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>HADOOP_MAPRED_HOME=/usr/local/src/hadoop-3.1.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>mapreduce.reduce.env<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>HADOOP_MAPRED_HOME=/usr/local/src/hadoop-3.1.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  &lt;/property
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>注意修改的各个<code>value</code>需要和<code>/etc/hosts</code>中的名称保持一致。</p><p>这三项配置一定要有：<code>yarn.app.mapreduce.am.env</code> <code>mapreduce.map.env</code> <code>mapreduce.reduce.env</code>否则在执行MR程序时会直接报错（hadoop3.1中已验证）。</p><p>具体错误参考：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://stackoverflow.com/questions/47599789/hadoop-pagerank-error-when-running">https://stackoverflow.com/questions/47599789/hadoop-pagerank-error-when-running</a></p><h2 id="配置workers文件"><a href="#配置workers文件" class="headerlink" title="配置workers文件"></a>配置workers文件</h2><p>列出所有workers的主机名。在<code>/usr/local/src/hadoop-3.1.0/etc/hadoop/workers</code>文件中写入：</p><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">node-master
node1
node2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure><p>注意：</p><ol><li>hadoop2.x配置的是slaves文件，这里有所改变。</li><li>此处的worker中写入了管理节点，因此启动HDFS之后也会在管理节点所在机器创建一个DataNode。如果不想在管理节点机器中开启DataNode，则删除workers文件中的node-master配置。</li></ol><p>此外，如果想在Hadoop集群中动态增加和删除节点，则更改此文件即可。</p><h1 id="配置内存分配"><a href="#配置内存分配" class="headerlink" title="配置内存分配"></a>配置内存分配</h1><p>内存分配在低RAM节点上可能会很棘手，因为默认值不适用于RAM少于8GB的节点，因此在使用sqoop等命令时调用的MapReduce程序会有如下类似的报错：</p><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">Application is added to the scheduler and is not yet activated. Queue&#39;s AM resource limit exceeded. Details : AM Partition &#x3D; &lt;DEFAULT_PARTITION&gt;; AM Resource Request &#x3D; &lt;memory:2048, vCores:1&gt;; Queue Resource Limit for AM &#x3D; &lt;memory:3072, vCores:1&gt;; User AM Resource Limit of the queue &#x3D; &lt;memory:3072, vCores:1&gt;; Queue AM Resource Usage &#x3D; &lt;memory:2048, vCores:1&gt;;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>这里将重点介绍如何为MapReduce作业分配内存，因为此次使用的ECS机器是4GB内存，因此为4GB RAM节点提供示例配置。</p><h2 id="内存分配属性"><a href="#内存分配属性" class="headerlink" title="内存分配属性"></a>内存分配属性</h2><p>YARN作业执行需要使用以下两种资源：</p><ul><li>Application Master (AM) ：负责监视应用程序并协调集群中的分布式执行程序。</li><li>Executors：一些由AM创建的Executors，用于真正的运行该作业。 对于MapReduce作业，executors会并行的执行map和reduce操作。</li></ul><p>两者都在从节点的容器中运行。 每个从节点都运行一个NodeManager守护进程，负责在节点上创建容器。 整个集群由一个ResourceManager管理，它根据容量要求和当前使用情况调度所有所有从节点上的容器分配。</p><p>需要正确配置四种类型的资源分配才能使群集正常工作。分别是：</p><ol><li>可以为单个节点上的YARN容器分配的内存大小。 这个限制应该高于其他所有的限制; 否则，容器分配会被拒绝，应用程序失败。 但是，它不应该是节点上的全部RAM。</li></ol><blockquote><p>这个值在<code>yarn-site.xml</code>中配置<code>yarn.nodemanager.resource.memory-mb</code>属性</p></blockquote><ol start="2"><li>单个容器可以消耗的内存大小以及允许的最小内存分配量。 一个容器永远不会超过最大容量，否则分配将失败，并且总是以最小分配量的倍数进行RAM分配。</li></ol><blockquote><p>这些值在<code>yarn-site.xml</code>中配置<code>yarn.scheduler.maximum-allocation-mb</code>和<code>yarn.scheduler.minimum-allocation-mb</code>属性。</p></blockquote><ol start="3"><li>分配给ApplicationMaster的内存大小。 是一个适合容器最大尺寸的常数值。</li></ol><blockquote><p>这个值在<code>mapred-site.xml</code>中配置<code>yarn.app.mapreduce.am.resource.mb</code>属性。</p></blockquote><ol start="4"><li>分配给map和reduce操作的内存大小。应该小于最大尺寸。</li></ol><blockquote><p>这是在<code>mapred-site.xml</code>中配置的，其属性为<code>mapreduce.map.memory.mb</code>和<code>mapreduce.reduce.memory.mb</code>。</p></blockquote><p>具体配置参数可以参见：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/ClusterSetup.html">https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/ClusterSetup.html</a></p><h2 id="各内存大小计算方式"><a href="#各内存大小计算方式" class="headerlink" title="各内存大小计算方式"></a>各内存大小计算方式</h2><p>下载内存计算脚本：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">wget</span> https://raw.githubusercontent.com/mahadevkonar/ambari-yarn-utils/master/yarn-utils/yarn-utils.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>使用方法：</p><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">python yarn-utils.py -c 16 -m 64 -d 4 -k True<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><ul><li>-c选项：cpu核数</li><li>-m选项：内存大小</li><li>-d选项：机器上的磁盘数量</li><li>-k选项：如果安装了HBase则设置为True，否则为False</li></ul><blockquote><p>其中：Core的数量可以通过<code>nproc</code>命令计算；内存大小可以通过<code>free -m</code>命令来计算需要换算为G;磁盘的数量可以通过<code>lsblk -s</code>或<code>sudo fdisk -l</code>命令来查看。</p></blockquote><p>计算完成之后，最后的脚本执行命令为：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hadoop@node-master:~$ python yarn-utils.py <span class="token parameter variable">-c</span> <span class="token number">2</span> <span class="token parameter variable">-m</span> <span class="token number">8</span> <span class="token parameter variable">-d</span> <span class="token number">1</span> <span class="token parameter variable">-k</span> False
 Using <span class="token assign-left variable">cores</span><span class="token operator">=</span><span class="token number">2</span> <span class="token assign-left variable">memory</span><span class="token operator">=</span>8GB <span class="token assign-left variable">disks</span><span class="token operator">=</span><span class="token number">1</span> <span class="token assign-left variable">hbase</span><span class="token operator">=</span>False
 Profile: <span class="token assign-left variable">cores</span><span class="token operator">=</span><span class="token number">2</span> <span class="token assign-left variable">memory</span><span class="token operator">=</span>6144MB <span class="token assign-left variable">reserved</span><span class="token operator">=</span>2GB <span class="token assign-left variable">usableMem</span><span class="token operator">=</span>6GB <span class="token assign-left variable">disks</span><span class="token operator">=</span><span class="token number">1</span>
 Num <span class="token assign-left variable">Container</span><span class="token operator">=</span><span class="token number">3</span>
 Container <span class="token assign-left variable">Ram</span><span class="token operator">=</span>2048MB
 Used <span class="token assign-left variable">Ram</span><span class="token operator">=</span>6GB
 Unused <span class="token assign-left variable">Ram</span><span class="token operator">=</span>2GB
 yarn.scheduler.minimum-allocation-mb<span class="token operator">=</span><span class="token number">2048</span>
 yarn.scheduler.maximum-allocation-mb<span class="token operator">=</span><span class="token number">6144</span>
 yarn.nodemanager.resource.memory-mb<span class="token operator">=</span><span class="token number">6144</span>
 <span class="token assign-left variable">mapreduce.map.memory.mb</span><span class="token operator">=</span><span class="token number">1024</span>
 <span class="token assign-left variable">mapreduce.map.java.opts</span><span class="token operator">=</span>-Xmx819m
 <span class="token assign-left variable">mapreduce.reduce.memory.mb</span><span class="token operator">=</span><span class="token number">2048</span>
 <span class="token assign-left variable">mapreduce.reduce.java.opts</span><span class="token operator">=</span>-Xmx1638m
 <span class="token assign-left variable">yarn.app.mapreduce.am.resource.mb</span><span class="token operator">=</span><span class="token number">1024</span>
 yarn.app.mapreduce.am.command-opts<span class="token operator">=</span>-Xmx819m
 <span class="token assign-left variable">mapreduce.task.io.sort.mb</span><span class="token operator">=</span><span class="token number">409</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h2 id="8GB节点的示例配置"><a href="#8GB节点的示例配置" class="headerlink" title="8GB节点的示例配置"></a>8GB节点的示例配置</h2><table><thead><tr><th>属性</th><th>值</th></tr></thead><tbody><tr><td>yarn.nodemanager.resource.memory-mb</td><td>6144</td></tr><tr><td>yarn.scheduler.maximum-allocation-mb</td><td>6144</td></tr><tr><td>yarn.scheduler.minimum-allocation-mb</td><td>2048</td></tr><tr><td>yarn.app.mapreduce.am.resource.mb</td><td>1024</td></tr><tr><td>mapreduce.map.memory.mb</td><td>1024</td></tr><tr><td>mapreduce.reduce.memory.mb</td><td>2048</td></tr></tbody></table><p>编辑 <code>/usr/local/src/hadoop-3.1.0/etc/hadoop/yarn-site.xml</code> 文件，并增加以下行：</p><figure><div class="code-wrapper"><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.resource.memory-mb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>6144<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.maximum-allocation-mb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>6144<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.minimum-allocation-mb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>2048<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.vmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>编辑<code>/usr/local/src/hadoop-3.1.0/etc/hadoop/mapred-site.xml</code>文件，并增加以下行：</p><figure><div class="code-wrapper"><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.app.mapreduce.am.resource.mb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>1024<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>mapreduce.map.memory.mb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>1024<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>mapreduce.reduce.memory.mb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>2048<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h1 id="配置从节点"><a href="#配置从节点" class="headerlink" title="配置从节点"></a>配置从节点</h1><p>复制hadoop的压缩包到所有从节点（也可以使用ftp手动上传）：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">scp</span> hadoop-3.1.0.tar.gz hadoop@node1:/usr/local/src/
<span class="token function">scp</span> hadoop-3.1.0.tar.gz hadoop@node2:/usr/local/src/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p>使用hadoop用户连接到所有的从节点，解压安装包：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span> /usr/local/src
<span class="token function">tar</span> <span class="token parameter variable">-xzvf</span> jdk-8u162-linux-x64.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p>复制主节点的所有hadoop配置文件到各从节点中：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">scp</span> /usr/local/src/hadoop-3.1.0/etc/hadoop/* hadoop@node1:/usr/local/src/hadoop-3.1.0/etc/hadoop/
<span class="token function">scp</span> /usr/local/src/hadoop-3.1.0/etc/hadoop/* hadoop@node2:/usr/local/src/hadoop-3.1.0/etc/hadoop/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><h1 id="格式化HDFS"><a href="#格式化HDFS" class="headerlink" title="格式化HDFS"></a>格式化HDFS</h1><p>HDFS需要像任何传统文件系统一样格式化。 在node-master上，运行以下命令：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hdfs namenode <span class="token parameter variable">-format</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h1 id="启动停止HDFS"><a href="#启动停止HDFS" class="headerlink" title="启动停止HDFS"></a>启动停止HDFS</h1><p>通过从node-master运行以下脚本启动HDFS：</p><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">start-dfs.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>这个命令会启动node-master上的NameNode和SecondaryNameNode，并且根据node1和node2上的配置文件分别启动node1和node2的DataNode。</p><p>使用jps命令检查每个节点上的进程是否启动：</p><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">24053 SecondaryNameNode
23721 NameNode
23850 DataNode
24205 Jps<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>（如果node-master上也启动了一个DataNode那么在node-master上也能看到NodeManager）</p><p>在node1上jps结果如下：</p><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">27387 Jps
27311 DataNode<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p>在node2上jps结果如下：</p><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">1314 Jps
1227 DataNode<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p>要停止主节点和从节点上的HDFS，请从node-master运行以下命令：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">stop-dfs.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>在hdfs启动之后，各种hdfs命令就都可以直接在集群上使用。</p><p>关于hdfs安全模式的解除：重启机器等操作时会导致hdfs处于安全模式，因此需要用命令解除：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hdfs dfsadmin <span class="token parameter variable">-safemode</span> leave<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h1 id="运行YARN"><a href="#运行YARN" class="headerlink" title="运行YARN"></a>运行YARN</h1><p>HDFS是一个分布式存储系统，它不提供任何服务来运行和调度集群中的任务。 这是YARN框架的作用。 以下部分是关于启动，监控和向YARN提交作业。</p><h2 id="启动停止YARN"><a href="#启动停止YARN" class="headerlink" title="启动停止YARN"></a>启动停止YARN</h2><p>运行以下脚本启动：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">start-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>使用jps命令检查各节点上正在运行的进程。除了前面的HDFS守护进程之外，还应该在node-master上看到ResourceManager，并在node1和node2上看到NodeManager。</p><p>要停止YARN，请在node-master上运行以下命令：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">stop-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h2 id="监控YARN"><a href="#监控YARN" class="headerlink" title="监控YARN"></a>监控YARN</h2><p>yarn命令提供实用的命令套件程序来管理YARN集群。 还可以使用以下命令打印正在运行的节点的报告：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">yarn</span> <span class="token function">node</span> <span class="token parameter variable">-list</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>如果运行错误，需要检查YARN的配置文件<code>hadoop/yarn-site.xml</code>是否配置错误。</p><p>可以使用以下命令获取正在运行的应用程序的列表：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">yarn</span> application <span class="token parameter variable">-list</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>要获得yarn命令的所有可用参数，请参阅<a target="_blank" rel="noopener external nofollow noreferrer" href="https://community.hortonworks.com/content/supportkb/49544/hdfs-client-fails-with-unknownhostexception-when-h.html">Apache YARN文档</a></p><p>与HDFS一样，YARN提供了一个友好的Web UI，默认端口为8088。 具体端口可通过yarn-site.xml文件里面的yarn.resourcemanager.webapp.address配置。示例地址如下：</p><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">http:&#x2F;&#x2F;120.77.239.67:18088&#x2F;cluster<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><h2 id="提交MapReduce作业至YARN"><a href="#提交MapReduce作业至YARN" class="headerlink" title="提交MapReduce作业至YARN"></a>提交MapReduce作业至YARN</h2><p>YARN作业被打包成jar文件，并提交给YARN用命令<code>yarn jar</code>执行。</p><hr><p>参考：</p><ul><li><a href="https://suncle.me/2018/04/16/Hadoop3-basic-installation-and-configuration/">https://suncle.me/2018/04/16/Hadoop3-basic-installation-and-configuration/</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.cnblogs.com/guoyuanwei/p/8583380.html">https://www.cnblogs.com/guoyuanwei/p/8583380.html</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://linode.com/docs/databases/hadoop/how-to-install-and-set-up-hadoop-cluster">https://linode.com/docs/databases/hadoop/how-to-install-and-set-up-hadoop-cluster</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="http://www.dajiangtai.com/community/18389.do">http://www.dajiangtai.com/community/18389.do</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.2cto.com/net/201610/557536.html">https://www.2cto.com/net/201610/557536.html</a></li></ul></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" class="category-chain-item">大数据</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/%E9%9B%86%E7%BE%A4/">#集群</a> <a href="/tags/%E6%90%AD%E5%BB%BA/">#搭建</a> <a href="/tags/YARN/">#YARN</a> <a href="/tags/Hadoop/">#Hadoop</a></div></div><div class="license-box my-3"><div class="license-title"><div>搭建Hadoop3集群</div><div>https://suncle.me/posts/1943368759/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Suncle Chen</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2018年5月3日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/" rel="external nofollow noreferrer"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/posts/2633130510/" title="Sqoop导入导出"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">Sqoop导入导出</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/posts/2322046866/" title="使用Python语言写Hadoop MapReduce程序"><span class="hidden-mobile">使用Python语言写Hadoop MapReduce程序</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><script type="text/javascript">Fluid.utils.loadComments("#comments",(function(){var t=document.documentElement.getAttribute("data-user-color-scheme");t="dark"===t?"github-dark":"github-light",window.UtterancesThemeLight="github-light",window.UtterancesThemeDark="github-dark";var e=document.createElement("script");e.setAttribute("src","https://utteranc.es/client.js"),e.setAttribute("repo","suncle1993/suncle1993.github.io"),e.setAttribute("issue-term","pathname"),e.setAttribute("label","utterances"),e.setAttribute("theme",t),e.setAttribute("crossorigin","anonymous"),document.getElementById("comments").appendChild(e)}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var o=jQuery("#board-ctn").offset().top;window.tocbot.init({tocSelector:"#toc-body",contentSelector:".markdown-body",headingSelector:CONFIG.toc.headingSelector||"h1,h2,h3,h4,h5,h6",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",collapseDepth:CONFIG.toc.collapseDepth||0,scrollSmooth:!0,headingsOffset:-o}),t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))</script><script src="https://lib.baomitu.com/prism/1.27.0/plugins/line-numbers/prism-line-numbers.min.js"></script><script src="https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var o=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),n=[];for(var i of o)n.push(".markdown-body > "+i.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(n.join(", "))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>