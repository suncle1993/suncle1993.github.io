<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png"><link rel="icon" href="/img/android-chrome-192x192.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="theme-color" content="#2f4154"><meta name="author" content="Suncle Chen"><meta name="keywords" content=""><meta name="description" content="从在用的四家cdn的大量日志中，统计出每场直播的流量数据，包括国内流量和海外流量。 获取日志目前已有的数据来源：四家cdn服务商。每个服务商都有自己不同的日志接口，不同的日志获取方式，可以把日志类型分为：  网宿日志、帝联日志、阿里日志，腾讯日志  直播日志、录播日志  hls日志、rtmp日志、rtmpdist日志、hdl日志，不同协议日志的域名都不相同。   各家厂商cdn日志的收集方法参见各"><meta property="og:type" content="article"><meta property="og:title" content="Hadoop项目：从cdn日志统计直播流量"><meta property="og:url" content="https://suncle.me/posts/3914716723/index.html"><meta property="og:site_name" content="Suncle"><meta property="og:description" content="从在用的四家cdn的大量日志中，统计出每场直播的流量数据，包括国内流量和海外流量。 获取日志目前已有的数据来源：四家cdn服务商。每个服务商都有自己不同的日志接口，不同的日志获取方式，可以把日志类型分为：  网宿日志、帝联日志、阿里日志，腾讯日志  直播日志、录播日志  hls日志、rtmp日志、rtmpdist日志、hdl日志，不同协议日志的域名都不相同。   各家厂商cdn日志的收集方法参见各"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://flume.apache.org/_images/UserGuide_image00.png"><meta property="article:published_time" content="2018-05-16T05:38:03.000Z"><meta property="article:modified_time" content="2022-08-26T02:44:02.303Z"><meta property="article:author" content="Suncle Chen"><meta property="article:tag" content="Hadoop"><meta property="article:tag" content="项目"><meta property="article:tag" content="统计"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="http://flume.apache.org/_images/UserGuide_image00.png"><meta name="referrer" content="no-referrer-when-downgrade"><title>Hadoop项目：从cdn日志统计直播流量 - Suncle</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/prism/1.27.0/plugins/line-numbers/prism-line-numbers.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"suncle.me",root:"/",version:"1.9.2",typing:{enable:!1,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!1,follow_dnt:!0,baidu:"41fc030db57d5570dd22f78997dc4a7e",google:"UA-72506112-1",gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="Suncle" type="application/atom+xml">
</head><body><header><div class="header-inner" style="height:60vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Suncle&#39;s Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/categories/newsletter/"><i class="iconfont icon-mail"></i> 周刊</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" target="_self" href="javascript:;" rel="external nofollow noreferrer" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><i class="iconfont icon-books"></i> 更多</a><div class="dropdown-menu" aria-labelledby="navbarDropdown"><a class="dropdown-item" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类 </a><a class="dropdown-item" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签 </a><a class="dropdown-item" href="/atom.xml"><i class="iconfont icon-rss-fill"></i> RSS</a></div></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" rel="external nofollow noreferrer" data-toggle="modal" data-target="#modalSearch" aria-label="Search">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" rel="external nofollow noreferrer" aria-label="Color Toggle">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/suncle-banner.jpg) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle">Hadoop项目：从cdn日志统计直播流量</span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2018-05-16 13:38" pubdate>2018年5月16日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 8.1k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 68 分钟</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar category-bar" style="margin-right:-1rem"><div class="category-list"><div class="category row nomargin-x"><a class="category-item list-group-item category-item-action col-10 col-md-11 col-xm-11" title="大数据" id="heading-2c657e7dce6effaecbb458deb45e800a" role="tab" data-toggle="collapse" href="#collapse-2c657e7dce6effaecbb458deb45e800a" aria-expanded="true">大数据 <span class="list-group-count">(12)</span> <i class="iconfont icon-arrowright"></i></a><div class="category-collapse collapse show" id="collapse-2c657e7dce6effaecbb458deb45e800a" role="tabpanel" aria-labelledby="heading-2c657e7dce6effaecbb458deb45e800a"><div class="category-post-list"><a href="/posts/847397348/" title="Clickhouse分布式集群搭建" class="list-group-item list-group-item-action"><span class="category-post">Clickhouse分布式集群搭建</span> </a><a href="/posts/4183645254/" title="Clickhouse创建分布式表以及表引擎介绍" class="list-group-item list-group-item-action"><span class="category-post">Clickhouse创建分布式表以及表引擎介绍</span> </a><a href="/posts/1205905514/" title="Clickhouse简介和性能对比" class="list-group-item list-group-item-action"><span class="category-post">Clickhouse简介和性能对比</span> </a><a href="/posts/4062227706/" title="Hadoop3单机和伪分布式模式安装配置" class="list-group-item list-group-item-action"><span class="category-post">Hadoop3单机和伪分布式模式安装配置</span> </a><a href="/posts/3530117200/" title="Hadoop、MapReduce、HDFS介绍" class="list-group-item list-group-item-action"><span class="category-post">Hadoop、MapReduce、HDFS介绍</span> </a><a href="/posts/3914716723/" title="Hadoop项目：从cdn日志统计直播流量" class="list-group-item list-group-item-action active"><span class="category-post">Hadoop项目：从cdn日志统计直播流量</span> </a><a href="/posts/2633130510/" title="Sqoop导入导出" class="list-group-item list-group-item-action"><span class="category-post">Sqoop导入导出</span> </a><a href="/posts/2322046866/" title="使用Python语言写Hadoop MapReduce程序" class="list-group-item list-group-item-action"><span class="category-post">使用Python语言写Hadoop MapReduce程序</span> </a><a href="/posts/1499000154/" title="大数据OLAP系统比较" class="list-group-item list-group-item-action"><span class="category-post">大数据OLAP系统比较</span> </a><a href="/posts/1943368759/" title="搭建Hadoop3集群" class="list-group-item list-group-item-action"><span class="category-post">搭建Hadoop3集群</span> </a><a href="/posts/2688010521/" title="数仓工作的简单介绍和对比" class="list-group-item list-group-item-action"><span class="category-post">数仓工作的简单介绍和对比</span> </a><a href="/posts/3266734121/" title="阿里云大数据基础组件调研" class="list-group-item list-group-item-action"><span class="category-post">阿里云大数据基础组件调研</span></a></div></div></div></div></aside></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">Hadoop项目：从cdn日志统计直播流量</h1><div class="markdown-body"><p>从在用的四家cdn的大量日志中，统计出每场直播的流量数据，包括国内流量和海外流量。</p><h1 id="获取日志"><a href="#获取日志" class="headerlink" title="获取日志"></a>获取日志</h1><p>目前已有的数据来源：四家cdn服务商。每个服务商都有自己不同的日志接口，不同的日志获取方式，可以把日志类型分为：</p><ul><li><p>网宿日志、帝联日志、阿里日志，腾讯日志</p></li><li><p>直播日志、录播日志</p></li><li><p>hls日志、rtmp日志、rtmpdist日志、hdl日志，不同协议日志的域名都不相同。</p></li></ul><p>各家厂商cdn日志的收集方法参见各自官网。获取到的日志示例文件名如下：</p><table><thead><tr><th>cdn_code</th><th>log_name</th></tr></thead><tbody><tr><td>netcenter</td><td>2017-12-06-2300-2330_rtmp-wsz.qukanvideo.com.cn.log.gz</td></tr><tr><td>dnion</td><td>hls-d.quklive.com_20180509_03_04.gz</td></tr><tr><td>alicdn</td><td>play-a.quklive.com_2017_12_07_1100_1200.gz</td></tr><tr><td>qukan-&gt;alicdn</td><td>recordcdn-sz.qukanvideo.com_2017_12_06_1800_1900.gz</td></tr><tr><td>tencent</td><td>2017120607_hangzhouqukan.cdn.log.gz</td></tr></tbody></table><p>可以从文件名判断属于日志所属的cdn代码和对应的协议。将cdn代码、播放类型代码、协议代码对应的关系直接存在字典中：</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">domain_protocol_dict <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token string">'recordcdn.quklive.com'</span><span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token string">'qukan'</span><span class="token punctuation">,</span> <span class="token string">'record'</span><span class="token punctuation">,</span> <span class="token string">'hls'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></figure><p>通过日志名称匹配到域名，并取得对应的cdn代码、播放类型代码、协议代码，然后对具体的日志做不同的正则处理。</p><span id="more"></span><h1 id="日志存入HDFS"><a href="#日志存入HDFS" class="headerlink" title="日志存入HDFS"></a>日志存入HDFS</h1><p><strong>直接使用hdfs命令拷贝到HDFS中</strong></p><p>通过日志下载程序调用接口下载到的日志可以使用以下命令直接拷贝到hdfs，拷贝成功一个日志，就删除对应的本地文件系统日志。示例命令如下：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hdfs dfs <span class="token parameter variable">-put</span> /tmp/2018-05-09-0000-0030_rtmpdist-wsz.qukanvideo.com.cn.log.gz cdn_log<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p><strong>使用分布式日志收集系统flume导入到HDFS中</strong></p><p>对于用户访问日志的采集，更多的是使用flume，并且会将采集的数据保存到HDFS中 。虽然本次项目日志不需要采用此种方式，但是也可以作为一个手段。flume在分布式日志收集上比较类似于ELK中的logstash，可以对比学习下。最简单（单agent）的数据流模型如下：</p><p><img src="http://flume.apache.org/_images/UserGuide_image00.png" srcset="/img/loading.gif" lazyload alt="flume data flow model"></p><p>具体使用方法参见：<a target="_blank" rel="noopener external nofollow noreferrer" href="http://flume.apache.org/FlumeUserGuide.html">Flume 1.8.0 User Guide</a></p><h1 id="hadoop压缩日志"><a href="#hadoop压缩日志" class="headerlink" title="hadoop压缩日志"></a>hadoop压缩日志</h1><p>各个cdn厂商提供的cdn日志都是gz格式的压缩日志，因此必须考虑对压缩日志的处理。Hadoop3 对于压缩格式是自动识别的。如果我们压缩的文件有相应压缩格式的扩展名（比如 lzo，gz，bzip2 等）。Hadoop 会根据压缩格式的扩展名自动选择相对应的解码器来解压数据，此过程完全是 Hadoop 自动处理，我们只需要确保输入的压缩文件有扩展名。因此这一步可以直接省略自行解压的操作。</p><p>但是需要注意在mapper环境变量中得到的输入文件的文件名是解压之前的文件名，也就是带压缩扩展名的。在hadoop3中可以通过以下变量验证：</p><figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os
input_file_path <span class="token operator">=</span> os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'mapreduce_map_input_file'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure><p>需要稍微注意的地方有两点：</p><ol><li>input_file_path保存的是文件在hdfs上的完整路径。 比如：<code>hdfs://node-master:9000/user/hadoop/cdn_log/2018-05-09-0100-0130_rtmpdist-wsz.qukanvideo.com.cn.log.gz</code></li><li>老版本的api为<code>map_input_file</code>，在集群上尝试了老版本的api，代码会报错。</li></ol><h1 id="MR程序"><a href="#MR程序" class="headerlink" title="MR程序"></a>MR程序</h1><p>具体代码参见Github：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/Flowsnow/hadoop-mapreduce-demo">https://github.com/Flowsnow/hadoop-mapreduce-demo</a></p><p>需要先确定mapper和redecer中间的数据格式，需要考虑到shuffle。因为最终是要按照live_id分组进行统计，因此live_id作为key，中间数据如下：</p><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">formatted_line &#x3D; &#39;\t&#39;.join([live_id, datetime_str, ip, up_flow, down_flow])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>使用<code>&#39;\t&#39;</code>分隔，ip用于后续判断属于国内还是海外。</p><h2 id="flow-statistic-mapper-py"><a href="#flow-statistic-mapper-py" class="headerlink" title="flow_statistic_mapper.py"></a>flow_statistic_mapper.py</h2><p>主要从各个cdn日志中筛选出有效的格式化数据，因此最多的操作就是对日志文件名和日志每一行进行正则匹配。</p><h2 id="flow-statistic-reducer-py"><a href="#flow-statistic-reducer-py" class="headerlink" title="flow_statistic_reducer.py"></a>flow_statistic_reducer.py</h2><p>根据ip查询是国内流量还是海外流量，对每场直播进行统计。</p><h2 id="代码调试"><a href="#代码调试" class="headerlink" title="代码调试"></a>代码调试</h2><p>使用linux管道、cat命令、sort命令综合使用进行调试，示例调试命令如下：</p><figure><div class="code-wrapper"><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> /tmp/2018-05-09-0000-0030_rtmpdist-wsz.qukanvideo.com.cn.log <span class="token operator">|</span> python flow_statistic_mapper.py <span class="token operator">|</span> <span class="token function">sort</span> <span class="token parameter variable">-t</span> <span class="token string">$'<span class="token entity" title="\t">\t</span>'</span> -k1,1 <span class="token operator">|</span> python flow_statistic_reducer.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure><p>因为原始日志是压缩格式的，因此调试时可以先把日志解压然后调试，相对应的mapper中的输入文件名称也会有变化，需要注意。</p><h2 id="MR调用"><a href="#MR调用" class="headerlink" title="MR调用"></a>MR调用</h2><p>命令和执行结果如下：</p><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">hadoop@node-master:~&#x2F;workspace&#x2F;flow_statistic$ hadoop jar &#x2F;usr&#x2F;local&#x2F;src&#x2F;hadoop-3.1.0&#x2F;share&#x2F;hadoop&#x2F;tools&#x2F;lib&#x2F;hadoop-streaming-3.1.0.jar -file flow_statistic_mapper.py -mapper &#39;python flow_statistic_mapper.py&#39; -file flow_statistic_reducer.py -reducer &#39;python flow_statistic_reducer.py&#39; -input all_cdn_logs&#x2F;*.gz -output output-flow
2018-05-15 19:14:26,975 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [flow_statistic_mapper.py, flow_statistic_reducer.py, &#x2F;tmp&#x2F;hadoop-unjar3114046136813781093&#x2F;] [] &#x2F;tmp&#x2F;streamjob6407868495582297159.jar tmpDir&#x3D;null
2018-05-15 19:14:28,667 INFO client.RMProxy: Connecting to ResourceManager at node-master&#x2F;120.77.239.67:18040
2018-05-15 19:14:28,944 INFO client.RMProxy: Connecting to ResourceManager at node-master&#x2F;120.77.239.67:18040
2018-05-15 19:14:29,587 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: &#x2F;tmp&#x2F;hadoop-yarn&#x2F;staging&#x2F;hadoop&#x2F;.staging&#x2F;job_1526300938491_0016
2018-05-15 19:14:30,598 INFO mapred.FileInputFormat: Total input files to process : 24
2018-05-15 19:14:30,741 INFO mapreduce.JobSubmitter: number of splits:24
2018-05-15 19:14:30,789 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-05-15 19:14:31,866 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1526300938491_0016
2018-05-15 19:14:31,868 INFO mapreduce.JobSubmitter: Executing with tokens: []
2018-05-15 19:14:32,071 INFO conf.Configuration: resource-types.xml not found
2018-05-15 19:14:32,072 INFO resource.ResourceUtils: Unable to find &#39;resource-types.xml&#39;.
2018-05-15 19:14:32,177 INFO impl.YarnClientImpl: Submitted application application_1526300938491_0016
2018-05-15 19:14:32,229 INFO mapreduce.Job: The url to track the job: http:&#x2F;&#x2F;node-master:18088&#x2F;proxy&#x2F;application_1526300938491_0016&#x2F;
2018-05-15 19:14:32,231 INFO mapreduce.Job: Running job: job_1526300938491_0016
2018-05-15 19:14:38,323 INFO mapreduce.Job: Job job_1526300938491_0016 running in uber mode : false
2018-05-15 19:14:38,325 INFO mapreduce.Job:  map 0% reduce 0%
2018-05-15 19:14:46,398 INFO mapreduce.Job:  map 8% reduce 0%
2018-05-15 19:14:50,419 INFO mapreduce.Job:  map 21% reduce 0%
2018-05-15 19:14:54,438 INFO mapreduce.Job:  map 25% reduce 0%
2018-05-15 19:14:56,449 INFO mapreduce.Job:  map 29% reduce 0%
2018-05-15 19:15:04,487 INFO mapreduce.Job:  map 38% reduce 0%
2018-05-15 19:15:05,492 INFO mapreduce.Job:  map 42% reduce 0%
2018-05-15 19:15:06,497 INFO mapreduce.Job:  map 50% reduce 0%
2018-05-15 19:15:14,534 INFO mapreduce.Job:  map 54% reduce 0%
2018-05-15 19:15:15,539 INFO mapreduce.Job:  map 58% reduce 0%
2018-05-15 19:15:21,569 INFO mapreduce.Job:  map 67% reduce 0%
2018-05-15 19:15:23,578 INFO mapreduce.Job:  map 71% reduce 0%
2018-05-15 19:15:24,582 INFO mapreduce.Job:  map 75% reduce 0%
2018-05-15 19:15:30,608 INFO mapreduce.Job:  map 75% reduce 25%
2018-05-15 19:15:31,613 INFO mapreduce.Job:  map 79% reduce 25%
2018-05-15 19:15:32,617 INFO mapreduce.Job:  map 88% reduce 25%
2018-05-15 19:15:34,626 INFO mapreduce.Job:  map 92% reduce 25%
2018-05-15 19:15:36,634 INFO mapreduce.Job:  map 92% reduce 31%
2018-05-15 19:15:39,646 INFO mapreduce.Job:  map 96% reduce 31%
2018-05-15 19:15:40,651 INFO mapreduce.Job:  map 100% reduce 31%
2018-05-15 19:15:41,659 INFO mapreduce.Job:  map 100% reduce 100%
2018-05-15 19:15:43,676 INFO mapreduce.Job: Job job_1526300938491_0016 completed successfully
2018-05-15 19:15:43,784 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read&#x3D;2208548
		FILE: Number of bytes written&#x3D;9857943
		FILE: Number of read operations&#x3D;0
		FILE: Number of large read operations&#x3D;0
		FILE: Number of write operations&#x3D;0
		HDFS: Number of bytes read&#x3D;864242
		HDFS: Number of bytes written&#x3D;303
		HDFS: Number of read operations&#x3D;77
		HDFS: Number of large read operations&#x3D;0
		HDFS: Number of write operations&#x3D;2
	Job Counters 
		Launched map tasks&#x3D;24
		Launched reduce tasks&#x3D;1
		Data-local map tasks&#x3D;24
		Total time spent by all maps in occupied slots (ms)&#x3D;167511
		Total time spent by all reduces in occupied slots (ms)&#x3D;32319
		Total time spent by all map tasks (ms)&#x3D;167511
		Total time spent by all reduce tasks (ms)&#x3D;32319
		Total vcore-milliseconds taken by all map tasks&#x3D;167511
		Total vcore-milliseconds taken by all reduce tasks&#x3D;32319
		Total megabyte-milliseconds taken by all map tasks&#x3D;343062528
		Total megabyte-milliseconds taken by all reduce tasks&#x3D;66189312
	Map-Reduce Framework
		Map input records&#x3D;87876
		Map output records&#x3D;35060
		Map output bytes&#x3D;2138422
		Map output materialized bytes&#x3D;2208686
		Input split bytes&#x3D;3864
		Combine input records&#x3D;0
		Combine output records&#x3D;0
		Reduce input groups&#x3D;9
		Reduce shuffle bytes&#x3D;2208686
		Reduce input records&#x3D;35060
		Reduce output records&#x3D;9
		Spilled Records&#x3D;70120
		Shuffled Maps &#x3D;24
		Failed Shuffles&#x3D;0
		Merged Map outputs&#x3D;24
		GC time elapsed (ms)&#x3D;3650
		CPU time spent (ms)&#x3D;23560
		Physical memory (bytes) snapshot&#x3D;8264720384
		Virtual memory (bytes) snapshot&#x3D;66202730496
		Total committed heap usage (bytes)&#x3D;6004146176
		Peak Map Physical memory (bytes)&#x3D;346320896
		Peak Map Virtual memory (bytes)&#x3D;2619580416
		Peak Reduce Physical memory (bytes)&#x3D;210169856
		Peak Reduce Virtual memory (bytes)&#x3D;3486892032
	Shuffle Errors
		BAD_ID&#x3D;0
		CONNECTION&#x3D;0
		IO_ERROR&#x3D;0
		WRONG_LENGTH&#x3D;0
		WRONG_MAP&#x3D;0
		WRONG_REDUCE&#x3D;0
	File Input Format Counters 
		Bytes Read&#x3D;860378
	File Output Format Counters 
		Bytes Written&#x3D;303<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure><h1 id="流量数据导出到Mysql"><a href="#流量数据导出到Mysql" class="headerlink" title="流量数据导出到Mysql"></a>流量数据导出到Mysql</h1><p>使用Sqoop导出HDFS中的流量数据到Mysql中，需要创建有对应字段的新表，具体使用参见Sqoop导入导出文档。</p><h1 id="hadoop-streaming错误排查"><a href="#hadoop-streaming错误排查" class="headerlink" title="hadoop streaming错误排查"></a>hadoop streaming错误排查</h1><p>使用hadoop streaming编写MR程序时最常见的错误：<strong>hadoop-streaming-subprocess-failed-with-code-1</strong></p><p>对应的需要检查以下几个问题：</p><ol><li>如果是通过.&#x2F;mapper.py的方式执行，则需要给mapper.py增加执行权限</li><li>python shell命令执行时，py文件头部需要指定<code>#!/usr/bin/env python</code></li><li>Python环境和程序依赖的第三方库需要在集群中的所有节点上安装</li></ol><p>上述几项没有问题之后，基本就是代码层面的问题了。需要逐层排查</p><hr><p>参考：</p><ul><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.cnblogs.com/joyeecheung/p/3841952.html">用python + hadoop streaming 编写分布式程序（三） – 自定义功能</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.cnblogs.com/joyeecheung/p/3757915.html">用python + hadoop streaming 编写分布式程序（一） – 原理介绍，样例程序与本地调试</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hadoop.apache.org/docs/r3.0.0/hadoop-streaming/HadoopStreaming.html">官方-Hadoop Streaming</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="http://grokbase.com/t/cloudera/cdh-user/132he822ep/hadoop-streaming-subprocess-failed-with-code-1">问题排查-Hadoop streaming - Subprocess failed with code 1</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="http://chenlly.com/2017/04/18/Hadoop-Python%E5%AE%9E%E7%8E%B0HadoopStreaming%E5%88%86%E7%BB%84%E5%92%8C%E4%BA%8C%E6%AC%A1%E6%8E%92%E5%BA%8F/">Hadoop-Python实现Hadoop Streaming分组和二次排序</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-compression-analysis/index.html">IBM-Hadoop 压缩实现分析</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="http://blog.51cto.com/balich/2067858">hadoop mapreduce开发实践之HDFS压缩文件（-cacheArchive）</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="http://icejoywoo.github.io/2015/09/28/introduction-to-hadoop-streaming.html">Hadoop Streaming入门</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="http://blog.51cto.com/xpleaf/2095836">大数据采集、清洗、处理：使用MapReduce进行离线数据分析完整案例</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/bitcarmanlee/article/details/51735053">hadoop 代码中获取文件名</a></li></ul></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" class="category-chain-item">大数据</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/Hadoop/">#Hadoop</a> <a href="/tags/%E9%A1%B9%E7%9B%AE/">#项目</a> <a href="/tags/%E7%BB%9F%E8%AE%A1/">#统计</a></div></div><div class="license-box my-3"><div class="license-title"><div>Hadoop项目：从cdn日志统计直播流量</div><div>https://suncle.me/posts/3914716723/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>Suncle Chen</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2018年5月16日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/" rel="external nofollow noreferrer"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"><a href="/posts/1598096655/" title="经典面试题"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">经典面试题</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/posts/2633130510/" title="Sqoop导入导出"><span class="hidden-mobile">Sqoop导入导出</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article id="comments" lazyload><script type="text/javascript">Fluid.utils.loadComments("#comments",(function(){var t=document.documentElement.getAttribute("data-user-color-scheme");t="dark"===t?"github-dark":"github-light",window.UtterancesThemeLight="github-light",window.UtterancesThemeDark="github-dark";var e=document.createElement("script");e.setAttribute("src","https://utteranc.es/client.js"),e.setAttribute("repo","suncle1993/suncle1993.github.io"),e.setAttribute("issue-term","pathname"),e.setAttribute("label","utterances"),e.setAttribute("theme",t),e.setAttribute("crossorigin","anonymous"),document.getElementById("comments").appendChild(e)}))</script><noscript>Please enable JavaScript to view the comments</noscript></article></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var o=jQuery("#board-ctn").offset().top;window.tocbot.init({tocSelector:"#toc-body",contentSelector:".markdown-body",headingSelector:CONFIG.toc.headingSelector||"h1,h2,h3,h4,h5,h6",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",collapseDepth:CONFIG.toc.collapseDepth||0,scrollSmooth:!0,headingsOffset:-o}),t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))</script><script src="https://lib.baomitu.com/prism/1.27.0/plugins/line-numbers/prism-line-numbers.min.js"></script><script src="https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var o=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),n=[];for(var i of o)n.push(".markdown-body > "+i.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(n.join(", "))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>